"""
Aplica√ß√£o Streamlit para visualiza√ß√£o e intera√ß√£o com o DataFlow Lab
Integrada com a plataforma unificada DataLab
"""

import json
import os
from datetime import datetime, timedelta

import pandas as pd
import plotly.express as px
import requests
import streamlit as st
from PIL import Image

# Configura√ß√£o da p√°gina (deve ser a primeira chamada Streamlit)
st.set_page_config(page_title="DataLab Unified Dashboard", page_icon="üöÄ", layout="wide")

# Importar m√≥dulos da plataforma unificada
import sys

sys.path.append("/opt/datalab")
sys.path.append(".")

try:
    from core.platform import DataLabCore
    from core.config import DataLabConfig
    from core.orchestrator import UnifiedOrchestrator
    from config.platform_config import get_platform_config, get_service_config
except ImportError:
    st.warning("M√≥dulos da plataforma unificada n√£o encontrados. Executando em modo fallback.")
    DataLabCore = None
    DataLabConfig = None
    UnifiedOrchestrator = None
    get_platform_config = lambda x, y: y
    get_service_config = lambda x: None


# Inicializar plataforma unificada
@st.cache_resource
def init_platform():
    """Inicializa a plataforma unificada com cache"""
    if DataLabCore and DataLabConfig and UnifiedOrchestrator:
        try:
            platform = DataLabCore()
            config_manager = DataLabConfig()
            orchestrator = UnifiedOrchestrator()
            st.success("‚úÖ Plataforma unificada inicializada com sucesso!")
            return platform, config_manager, orchestrator
        except Exception as e:
            st.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel inicializar plataforma unificada: {e}")
            return None, None, None
    return None, None, None


platform, config_manager, orchestrator = init_platform()

# T√≠tulo e descri√ß√£o
st.title("ÔøΩ DataLab - Plataforma Unificada")
st.markdown(
    """
    Painel de controle unificado para monitoramento e intera√ß√£o com a plataforma DataLab.
    Este dashboard integra todos os servi√ßos e permite gest√£o centralizada de pipelines, 
    dados e monitoramento em tempo real.
"""
)

# Status da Plataforma Unificada
if platform:
    st.info("üåü **Plataforma Unificada Ativa** - Todos os recursos avan√ßados habilitados")
    
    # Mostrar m√©tricas da plataforma
    col1, col2, col3, col4 = st.columns(4)
    
    try:
        metrics = platform.get_unified_metrics()
        platform_status = platform.get_platform_status()
        with col1:
            st.metric("Servi√ßos Configurados", len(platform_status.get('services', {})))
        with col2:
            st.metric("Pipelines Monitorados", len(platform.get_pipelines_status()))
        with col3:
            st.metric("Health Score", f"{metrics.get('overall_health', 95)}%")
        with col4:
            st.metric("Uptime", metrics.get("uptime", "N/A"))
    except Exception as e:
        st.warning(f"N√£o foi poss√≠vel carregar m√©tricas da plataforma: {e}")
else:
    st.warning("‚ö†Ô∏è **Modo Fallback** - Plataforma unificada n√£o dispon√≠vel")

# Sidebar com navega√ß√£o
st.sidebar.title("üéõÔ∏è Painel de Controle")

if platform:
    st.sidebar.success("‚úÖ Plataforma Unificada")
else:
    st.sidebar.warning("‚ö†Ô∏è Modo Fallback")

page = st.sidebar.radio(
    "Selecione uma p√°gina",
    ["Vis√£o Geral", "Plataforma Unificada", "Camadas", "Pipelines", "Prefect Flows", "Servi√ßos", "ML Models", "Configura√ß√£o"],
)


# Status dos servi√ßos
@st.cache_data(ttl=60)  # Cache por 60 segundos
def check_service_status(url):
    try:
        response = requests.get(url, timeout=1)
        if response.status_code < 400:
            return "üü¢ Online"
        else:
            return "üü† Problema"
    except:
        return "üî¥ Offline"


# Fun√ß√µes para simular dados
@st.cache_data(ttl=300)  # Cache por 5 minutos
def get_sample_data():
    # Dados simulados para demonstra√ß√£o
    dates = pd.date_range(end=datetime.now(), periods=30).tolist()
    bronze_counts = [100 + i * 10 + int(i**1.5) for i in range(30)]
    silver_counts = [bronze_counts[i] * 0.8 for i in range(30)]
    gold_counts = [silver_counts[i] * 0.6 for i in range(30)]

    df = pd.DataFrame(
        {
            "date": dates,
            "bronze": bronze_counts,
            "silver": silver_counts,
            "gold": gold_counts,
        }
    )

    return df


@st.cache_data
def get_pipeline_data():
    # Dados simulados para demonstra√ß√£o de pipelines
    now = datetime.now()
    pipelines = [
        {
            "name": "ETL_Financial",
            "last_run": (now - timedelta(minutes=30)).strftime("%Y-%m-%d %H:%M:%S"),
            "status": "Sucesso",
            "duration": "5m 12s",
            "records": 15420,
        },
        {
            "name": "Stock_Data_Ingestion",
            "last_run": (now - timedelta(hours=2)).strftime("%Y-%m-%d %H:%M:%S"),
            "status": "Sucesso",
            "duration": "3m 45s",
            "records": 8750,
        },
        {
            "name": "Customer_Analytics",
            "last_run": (now - timedelta(hours=8)).strftime("%Y-%m-%d %H:%M:%S"),
            "status": "Falha",
            "duration": "2m 30s",
            "records": 0,
        },
        {
            "name": "Product_Metrics",
            "last_run": (now - timedelta(hours=12)).strftime("%Y-%m-%d %H:%M:%S"),
            "status": "Sucesso",
            "duration": "8m 20s",
            "records": 25300,
        },
        {
            "name": "ML_Training_Daily",
            "last_run": (now - timedelta(hours=24)).strftime("%Y-%m-%d %H:%M:%S"),
            "status": "Sucesso",
            "duration": "15m 45s",
            "records": 42680,
        },
    ]
    return pd.DataFrame(pipelines)


@st.cache_data
def get_model_data():
    # Dados simulados sobre modelos de ML
    models = [
        {
            "name": "price_prediction_v1",
            "type": "RandomForest",
            "accuracy": 0.87,
            "created": "2025-05-08",
            "status": "Production",
        },
        {
            "name": "customer_churn_v2",
            "type": "XGBoost",
            "accuracy": 0.92,
            "created": "2025-05-09",
            "status": "Staging",
        },
        {
            "name": "product_recommendation",
            "type": "Neural Network",
            "accuracy": 0.78,
            "created": "2025-05-10",
            "status": "Development",
        },
        {
            "name": "anomaly_detector_v1",
            "type": "Isolation Forest",
            "accuracy": 0.81,
            "created": "2025-05-07",
            "status": "Production",
        },
    ]
    return pd.DataFrame(models)


# P√°gina principal - Vis√£o Geral
if page == "Vis√£o Geral":
    st.header("Vis√£o Geral do DataFlow Lab")

    # Status dos servi√ßos em cards
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.info("**MinIO**")
        st.write(check_service_status("http://minio:9000"))
    with col2:
        st.info("**Spark**")
        st.write(check_service_status("http://spark-master:8080"))
    with col3:
        st.info("**MLflow**")
        st.write(check_service_status("http://mlflow:5000"))
    with col4:
        st.info("**Prefect**")
        st.write(check_service_status("http://prefect:4200"))

    # Gr√°fico de dados
    st.subheader("Volume de Dados por Camada")
    df = get_sample_data()

    chart = px.line(
        df,
        x="date",
        y=["bronze", "silver", "gold"],
        title="Evolu√ß√£o do Volume de Dados",
        labels={"value": "Registros", "date": "Data", "variable": "Camada"},
        color_discrete_map={
            "bronze": "#cd7f32",
            "silver": "#c0c0c0",
            "gold": "#ffd700",
        },
    )
    st.plotly_chart(chart, use_container_width=True)

    # √öltimos pipelines executados
    st.subheader("√öltimos Pipelines Executados")
    pipelines_df = get_pipeline_data()

    # Colorir o status
    def color_status(val):
        color = "green" if val == "Sucesso" else "red"
        return f"background-color: {color}; color: white"

    styled_df = pipelines_df.style.map(color_status, subset=["status"])

    st.dataframe(styled_df, use_container_width=True)

# P√°gina de camadas
elif page == "Camadas":
    st.header("Arquitetura Medallion")

    layer_tabs = st.tabs(["Bronze", "Silver", "Gold"])

    with layer_tabs[0]:
        st.subheader("Camada Bronze")
        st.markdown(
            """
        A camada Bronze cont√©m dados brutos ingeridos sem modifica√ß√µes ou com modifica√ß√µes m√≠nimas.
        Principais caracter√≠sticas:
        - Preserva os dados originais para auditoria e recupera√ß√£o
        - Inclui metadados como hora de ingest√£o e fonte
        - Armazenada em formato Delta Lake para garantias ACID
        """
        )

        st.info("**Tabelas na camada Bronze**")
        bronze_tables = [
            "raw_financial_data",
            "raw_stock_data",
            "raw_customer_data",
            "raw_logs",
        ]
        for table in bronze_tables:
            st.code(f"s3a://bronze/{table}")

    with layer_tabs[1]:
        st.subheader("Camada Silver")
        st.markdown(
            """
        A camada Silver cont√©m dados limpos, validados e transformados.
        Principais caracter√≠sticas:
        - Dados normalizados e estruturados
        - Valores nulos tratados e anomalias removidas
        - Esquema consistente e documentado
        """
        )

        st.info("**Tabelas na camada Silver**")
        silver_tables = [
            "clean_financial_data",
            "clean_stock_data",
            "clean_customer_data",
        ]
        for table in silver_tables:
            st.code(f"s3a://silver/{table}")

    with layer_tabs[2]:
        st.subheader("Camada Gold")
        st.markdown(
            """
        A camada Gold cont√©m dados refinados e agregados para consumo.
        Principais caracter√≠sticas:
        - Tabelas e views preparadas para an√°lise
        - Dados agregados e modelados para casos de uso espec√≠ficos
        - Otimizados para consulta e an√°lise
        """
        )

        st.info("**Tabelas na camada Gold**")
        gold_tables = [
            "financial_metrics",
            "stock_analysis",
            "customer_segments",
            "dashboards",
        ]
        for table in gold_tables:
            st.code(f"s3a://gold/{table}")

# P√°gina de Pipelines
elif page == "Pipelines":
    st.header("Pipelines de Dados")
    st.markdown(
        """
    Aqui voc√™ pode monitorar e gerenciar os pipelines de dados da plataforma.
    Os pipelines s√£o orquestrados com Prefect e processam dados atrav√©s das camadas.
    """
    )

    # Formul√°rio para criar um novo pipeline
    with st.expander("Criar Novo Pipeline"):
        with st.form("new_pipeline_form"):
            st.subheader("Novo Pipeline")
            name = st.text_input("Nome do Pipeline")
            source_type = st.selectbox(
                "Tipo de Fonte",
                ["PostgreSQL", "MySQL", "API", "CSV", "Parquet", "JSON"],
            )
            target_table = st.text_input("Tabela de Destino")
            schedule = st.selectbox(
                "Agendamento", ["Di√°rio", "Hor√°rio", "Semanal", "Mensal", "Manual"]
            )

            # Adicionar bot√£o para enviar
            submitted = st.form_submit_button("Criar Pipeline")
            if submitted:
                st.success(f"Pipeline '{name}' criado com sucesso!")

    # Lista de pipelines
    st.subheader("Pipelines Ativos")
    pipelines_df = get_pipeline_data()

    # Filtros
    status_filter = st.selectbox("Filtrar por Status", ["Todos", "Sucesso", "Falha"])
    if status_filter != "Todos":
        pipelines_df = pipelines_df[pipelines_df["status"] == status_filter]

    # Mostrar tabela
    st.dataframe(pipelines_df, use_container_width=True)

    # Detalhes do pipeline
    st.subheader("Detalhes do Pipeline")
    selected_pipeline = st.selectbox(
        "Selecione um pipeline para ver detalhes", pipelines_df["name"].tolist()
    )

    # Bot√µes de a√ß√£o
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("Executar Agora"):
            st.info(f"Executando pipeline {selected_pipeline}...")
            st.success(f"Pipeline {selected_pipeline} iniciado com sucesso!")
    with col2:
        st.button("Editar Pipeline")
    with col3:
        st.button("Pausar Pipeline")

    # Mostrar logs simulados
    st.subheader("Logs do Pipeline")
    st.code(
        f"""
    [2025-05-11 08:30:15] INFO: Pipeline {selected_pipeline} iniciado
    [2025-05-11 08:30:18] INFO: Conectando √† fonte de dados
    [2025-05-11 08:30:25] INFO: Dados extra√≠dos com sucesso (12345 registros)
    [2025-05-11 08:31:05] INFO: Dados transformados
    [2025-05-11 08:32:10] INFO: Dados carregados na camada destino
    [2025-05-11 08:32:15] INFO: Pipeline conclu√≠do com sucesso
    """
    )

# P√°gina de Prefect Flows
elif page == "Prefect Flows":
    st.header("üîÑ Monitoramento de Fluxos Prefect")

    # Status geral do Prefect
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("üîÑ Fluxos Ativos", "12")
    with col2:
        st.metric("‚úÖ Execu√ß√µes Hoje", "47")
    with col3:
        st.metric("‚ö†Ô∏è Falhas", "2")
    with col4:
        st.metric("‚è±Ô∏è Tempo M√©dio", "8m 32s")

    # Abas para diferentes visualiza√ß√µes
    tab1, tab2, tab3, tab4 = st.tabs(
        ["üìä Dashboard", "üîÑ Fluxos", "üìà M√©tricas", "üö® Alertas"]
    )

    with tab1:
        st.subheader("Status dos Principais Fluxos")

        flows_status = [
            {
                "Nome": "Medallion ETL Pipeline",
                "Status": "‚úÖ Ativo",
                "Pr√≥xima Execu√ß√£o": "06:00",
                "√öltima Dura√ß√£o": "12m 45s",
            },
            {
                "Nome": "MLOps Training Pipeline",
                "Status": "‚è∏Ô∏è Pausado",
                "Pr√≥xima Execu√ß√£o": "Domingo 02:00",
                "√öltima Dura√ß√£o": "35m 20s",
            },
            {
                "Nome": "Real-time Monitoring",
                "Status": "‚úÖ Ativo",
                "Pr√≥xima Execu√ß√£o": "A cada 5min",
                "√öltima Dura√ß√£o": "2m 15s",
            },
            {
                "Nome": "Data Lake Maintenance",
                "Status": "‚úÖ Ativo",
                "Pr√≥xima Execu√ß√£o": "S√°bado 03:00",
                "√öltima Dura√ß√£o": "18m 32s",
            },
        ]

        flows_df = pd.DataFrame(flows_status)
        st.dataframe(flows_df, use_container_width=True)

        # Gr√°fico de execu√ß√µes por hora
        st.subheader("Execu√ß√µes por Hora (√öltimas 24h)")

        hours = list(range(24))
        executions = [
            3,
            2,
            1,
            0,
            0,
            0,
            8,
            5,
            7,
            12,
            15,
            18,
            22,
            19,
            16,
            14,
            11,
            9,
            7,
            5,
            4,
            3,
            2,
            1,
        ]

        hourly_data = pd.DataFrame({"Hora": hours, "Execu√ß√µes": executions})
        chart = px.bar(
            hourly_data,
            x="Hora",
            y="Execu√ß√µes",
            title="Distribui√ß√£o de Execu√ß√µes de Fluxos",
            color="Execu√ß√µes",
            color_continuous_scale="viridis",
        )
        st.plotly_chart(chart, use_container_width=True)

    with tab2:
        st.subheader("Detalhes dos Fluxos")

        # Seletor de fluxo
        selected_flow = st.selectbox(
            "Selecione um fluxo:",
            [
                "Medallion ETL Pipeline",
                "MLOps Training Pipeline",
                "Real-time Monitoring",
                "Data Lake Maintenance",
            ],
        )

        if selected_flow == "Medallion ETL Pipeline":
            st.info("**Descri√ß√£o:** Pipeline completo ETL com arquitetura Medallion")
            st.write("**Agendamento:** Di√°rio √†s 06:00")
            st.write("**Dura√ß√£o M√©dia:** 12m 45s")
            st.write("**Taxa de Sucesso:** 94.2%")

            # Hist√≥rico de execu√ß√µes
            execution_history = [
                {
                    "Data": "2025-07-09 06:00",
                    "Status": "‚úÖ Sucesso",
                    "Dura√ß√£o": "11m 23s",
                    "Registros": "125,430",
                },
                {
                    "Data": "2025-07-08 06:00",
                    "Status": "‚úÖ Sucesso",
                    "Dura√ß√£o": "13m 15s",
                    "Registros": "132,891",
                },
                {
                    "Data": "2025-07-07 06:00",
                    "Status": "‚ùå Falha",
                    "Dura√ß√£o": "8m 42s",
                    "Registros": "0",
                },
                {
                    "Data": "2025-07-06 06:00",
                    "Status": "‚úÖ Sucesso",
                    "Dura√ß√£o": "14m 07s",
                    "Registros": "118,765",
                },
            ]

            st.subheader("Hist√≥rico de Execu√ß√µes")
            history_df = pd.DataFrame(execution_history)
            st.dataframe(history_df, use_container_width=True)

        elif selected_flow == "Real-time Monitoring":
            st.info("**Descri√ß√£o:** Monitoramento em tempo real da plataforma DataLab")
            st.write("**Agendamento:** A cada 5 minutos")
            st.write("**Dura√ß√£o M√©dia:** 2m 15s")
            st.write("**Taxa de Sucesso:** 99.1%")

            # M√©tricas em tempo real
            st.subheader("M√©tricas em Tempo Real")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("T√≥picos Kafka", "3", "0")
            with col2:
                st.metric("Servi√ßos Online", "6/6", "0")
            with col3:
                st.metric("Score Qualidade", "94%", "+2%")

    with tab3:
        st.subheader("M√©tricas de Performance")

        # M√©tricas de dura√ß√£o
        col1, col2 = st.columns(2)

        with col1:
            st.subheader("Dura√ß√£o por Tipo de Fluxo")
            duration_data = {
                "Tipo": ["ETL", "MLOps", "Monitoramento", "Manuten√ß√£o"],
                "Dura√ß√£o M√©dia (min)": [12.8, 35.4, 2.3, 18.6],
            }
            duration_df = pd.DataFrame(duration_data)
            chart = px.bar(
                duration_df,
                x="Tipo",
                y="Dura√ß√£o M√©dia (min)",
                title="Dura√ß√£o M√©dia por Tipo",
            )
            st.plotly_chart(chart, use_container_width=True)

        with col2:
            st.subheader("Taxa de Sucesso por Fluxo")
            success_data = {
                "Fluxo": ["Medallion ETL", "MLOps", "Monitoring", "Maintenance"],
                "Taxa de Sucesso (%)": [94.2, 87.5, 99.1, 91.8],
            }
            success_df = pd.DataFrame(success_data)
            chart = px.pie(
                success_df,
                names="Fluxo",
                values="Taxa de Sucesso (%)",
                title="Taxa de Sucesso",
            )
            st.plotly_chart(chart, use_container_width=True)

        # Tabela de recursos
        st.subheader("Uso de Recursos")
        resources_data = [
            {
                "Fluxo": "Medallion ETL",
                "CPU M√©dio": "1.2 cores",
                "Mem√≥ria M√©dia": "2.1 GB",
                "I/O": "Alto",
            },
            {
                "Fluxo": "MLOps Training",
                "CPU M√©dio": "2.8 cores",
                "Mem√≥ria M√©dia": "4.5 GB",
                "I/O": "M√©dio",
            },
            {
                "Fluxo": "Monitoring",
                "CPU M√©dio": "0.3 cores",
                "Mem√≥ria M√©dia": "0.5 GB",
                "I/O": "Baixo",
            },
            {
                "Fluxo": "Maintenance",
                "CPU M√©dio": "1.8 cores",
                "Mem√≥ria M√©dia": "3.2 GB",
                "I/O": "Alto",
            },
        ]
        resources_df = pd.DataFrame(resources_data)
        st.dataframe(resources_df, use_container_width=True)

    with tab4:
        st.subheader("üö® Alertas e Notifica√ß√µes")

        # Alertas recentes
        alerts = [
            {
                "Timestamp": "2025-07-09 14:32",
                "Severidade": "‚ö†Ô∏è Warning",
                "Mensagem": "MLOps pipeline com dura√ß√£o acima da m√©dia",
                "Status": "Ativo",
            },
            {
                "Timestamp": "2025-07-09 12:15",
                "Severidade": "‚ùå Error",
                "Mensagem": "Falha na conex√£o com Kafka",
                "Status": "Resolvido",
            },
            {
                "Timestamp": "2025-07-09 08:45",
                "Severidade": "‚ÑπÔ∏è Info",
                "Mensagem": "Manuten√ß√£o programada conclu√≠da",
                "Status": "Resolvido",
            },
            {
                "Timestamp": "2025-07-08 19:30",
                "Severidade": "‚ö†Ô∏è Warning",
                "Mensagem": "Uso de mem√≥ria alto no Spark",
                "Status": "Monitorando",
            },
        ]

        alerts_df = pd.DataFrame(alerts)
        st.dataframe(alerts_df, use_container_width=True)

        # Configura√ß√µes de alertas
        st.subheader("Configura√ß√µes de Alertas")
        col1, col2 = st.columns(2)

        with col1:
            st.checkbox("Email notifications", value=True)
            st.checkbox("Slack notifications", value=False)
            st.checkbox("Teams notifications", value=False)

        with col2:
            st.slider("Threshold de dura√ß√£o (minutos)", 5, 60, 30)
            st.slider("Threshold de falhas consecutivas", 1, 10, 3)

        if st.button("üíæ Salvar Configura√ß√µes"):
            st.success("Configura√ß√µes salvas com sucesso!")

# P√°gina de Servi√ßos
elif page == "Servi√ßos":
    st.header("Servi√ßos da Plataforma")
    st.markdown(
        """
    Aqui voc√™ pode monitorar e acessar os diversos servi√ßos que comp√µem a plataforma DataFlow Lab.
    """
    )

    # Cart√µes para os servi√ßos com links
    col1, col2 = st.columns(2)

    with col1:
        st.info("### MinIO")
        st.write("Sistema de armazenamento de objetos compat√≠vel com S3")
        st.write("- Console: [http://localhost:9001](http://localhost:9001)")
        st.write("- Status: ", check_service_status("http://minio:9000"))
        if st.button("Inicializar Buckets"):
            st.success("Buckets bronze, silver e gold criados com sucesso!")

    with col2:
        st.info("### Apache Spark")
        st.write("Framework de processamento distribu√≠do")
        st.write("- UI: [http://localhost:8080](http://localhost:8080)")
        st.write("- Status: ", check_service_status("http://spark-master:8080"))
        if st.button("Ver Aplica√ß√µes Ativas"):
            st.code(
                """
            ApplicationID: spark-20250511123456-0001
            Nome: medallion_example
            Estado: RUNNING
            Cores: 2
            Mem√≥ria: 2.0 GB
            """
            )

    col3, col4 = st.columns(2)

    with col3:
        st.info("### MLflow")
        st.write("Plataforma para gerenciamento do ciclo de vida de ML")
        st.write("- UI: [http://localhost:5000](http://localhost:5000)")
        st.write("- Status: ", check_service_status("http://mlflow:5000"))
        if st.button("Ver Experimentos"):
            st.dataframe(
                {
                    "ID": [1, 2, 3],
                    "Nome": ["price_prediction", "customer_churn", "anomaly_detection"],
                    "Execu√ß√µes": [15, 8, 23],
                }
            )

    with col4:
        st.info("### Prefect")
        st.write("Orquestrador de fluxos de dados")
        st.write("- UI: [http://localhost:4200](http://localhost:4200)")
        st.write("- Status: ", check_service_status("http://prefect:4200"))
        if st.button("Ver Fluxos"):
            st.dataframe(
                {
                    "Nome": ["medallion_pipeline", "etl_di√°rio", "treinamento_ml"],
                    "Estado": ["Healthy", "Healthy", "Warning"],
                    "√öltima Execu√ß√£o": [
                        "11/05/2025 08:30",
                        "11/05/2025 04:00",
                        "10/05/2025 22:00",
                    ],
                }
            )

# P√°gina de ML Models
elif page == "ML Models":
    st.header("Machine Learning Models")
    st.markdown(
        """
    Aqui voc√™ pode monitorar e gerenciar os modelos de Machine Learning da plataforma.
    Os modelos s√£o treinados com dados da camada Gold e rastreados com MLflow.
    """
    )

    # Lista de modelos
    models_df = get_model_data()

    # Filtros
    model_status = st.selectbox(
        "Filtrar por Status", ["Todos", "Production", "Staging", "Development"]
    )
    if model_status != "Todos":
        models_df = models_df[models_df["status"] == model_status]

    # Mostrar tabela
    st.dataframe(models_df, use_container_width=True)

    # Gr√°fico de barras para acur√°cia
    fig = px.bar(
        models_df,
        x="name",
        y="accuracy",
        color="type",
        title="Acur√°cia dos Modelos",
        labels={"name": "Nome do Modelo", "accuracy": "Acur√°cia", "type": "Tipo"},
    )
    st.plotly_chart(fig, use_container_width=True)

    # Formul√°rio para treinar novo modelo
    with st.expander("Treinar Novo Modelo"):
        with st.form("train_model_form"):
            st.subheader("Novo Modelo")
            name = st.text_input("Nome do Modelo")
            model_type = st.selectbox(
                "Tipo de Modelo",
                [
                    "RandomForest",
                    "XGBoost",
                    "Neural Network",
                    "Linear Regression",
                    "Isolation Forest",
                ],
            )
            dataset = st.selectbox(
                "Dataset de Treinamento",
                [
                    "gold.financial_metrics",
                    "gold.customer_segments",
                    "gold.stock_analysis",
                ],
            )
            target = st.text_input("Vari√°vel Alvo")

            # Adicionar bot√£o para enviar
            submitted = st.form_submit_button("Treinar Modelo")
            if submitted:
                st.success(f"Treinamento do modelo '{name}' iniciado!")

    # Bot√£o para implementar modelo em produ√ß√£o
    selected_model = st.selectbox(
        "Selecione um modelo para a√ß√£o", models_df["name"].tolist()
    )

    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("Promover para Produ√ß√£o"):
            st.success(f"Modelo {selected_model} promovido para produ√ß√£o!")
    with col2:
        st.button("Ver M√©tricas Detalhadas")
    with col3:
        st.button("Baixar Modelo")

elif page == "Plataforma Unificada":
    st.header("üåü Plataforma Unificada - Gest√£o Centralizada")
    
    if not platform:
        st.error("‚ùå Plataforma unificada n√£o est√° dispon√≠vel. Certifique-se de que os m√≥dulos core est√£o instalados.")
        st.info("Para ativar a plataforma unificada, execute: `python setup.sh`")
        st.stop()
    
    # Tabs para diferentes aspectos da plataforma
    tab1, tab2, tab3, tab4 = st.tabs(["üè• Health Check", "üìä M√©tricas", "üîÑ Pipelines", "‚öôÔ∏è Configura√ß√£o"])
    
    with tab1:
        st.subheader("Health Check dos Servi√ßos")
        
        if st.button("üîÑ Verificar Health de Todos os Servi√ßos"):
            with st.spinner("Verificando health dos servi√ßos..."):
                try:
                    health_results = {}
                    services = ["spark", "kafka", "minio", "mlflow", "prefect", "jupyter"]
                    
                    for service in services:
                        try:
                            health = platform.check_service_health(service)
                            health_results[service] = health
                        except Exception as e:
                            health_results[service] = {"status": "error", "error": str(e)}
                    
                    # Mostrar resultados
                    for service, health in health_results.items():
                        status = health.get("status", "unknown")
                        if status == "healthy":
                            st.success(f"‚úÖ {service.upper()}: Saud√°vel")
                        elif status == "warning":
                            st.warning(f"‚ö†Ô∏è {service.upper()}: Aten√ß√£o")
                        else:
                            st.error(f"‚ùå {service.upper()}: Problema")
                        
                        if "details" in health:
                            st.json(health["details"])
                            
                except Exception as e:
                    st.error(f"Erro ao verificar health: {e}")
    
    with tab2:
        st.subheader("M√©tricas da Plataforma")
        
        try:
            metrics = platform.get_metrics()
            
            # M√©tricas principais
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Servi√ßos Registrados", len(platform.service_registry))
            with col2:
                st.metric("Pipelines Ativos", metrics.get("active_pipelines", 0))
            with col3:
                st.metric("Erro Rate", f"{metrics.get('error_rate', 0):.1f}%")
            with col4:
                st.metric("Throughput", f"{metrics.get('throughput', 0)} req/s")
            
            # Gr√°fico de m√©tricas
            if "historical_metrics" in metrics:
                df_metrics = pd.DataFrame(metrics["historical_metrics"])
                fig = px.line(df_metrics, x="timestamp", y="value", color="metric", 
                            title="M√©tricas da Plataforma ao Longo do Tempo")
                st.plotly_chart(fig, use_container_width=True)
            
            # M√©tricas detalhadas em JSON
            with st.expander("üîç M√©tricas Detalhadas (JSON)"):
                st.json(metrics)
                
        except Exception as e:
            st.error(f"Erro ao carregar m√©tricas: {e}")
    
    with tab3:
        st.subheader("Gest√£o de Pipelines")
        
        if orchestrator:
            # Mostrar pipelines registrados
            st.write("**Pipelines Registrados:**")
            
            try:
                pipelines = orchestrator.registered_pipelines
                if pipelines:
                    df_pipelines = pd.DataFrame([
                        {
                            "Nome": name,
                            "Tasks": len(pipeline["tasks"]),
                            "Schedule": pipeline.get("schedule", "Manual"),
                            "Enabled": pipeline.get("enabled", False),
                            "√öltimo Sucesso": pipeline.get("success_count", 0),
                            "Falhas": pipeline.get("failure_count", 0)
                        }
                        for name, pipeline in pipelines.items()
                    ])
                    st.dataframe(df_pipelines, use_container_width=True)
                    
                    # Controles de pipeline
                    selected_pipeline = st.selectbox("Selecionar Pipeline", list(pipelines.keys()))
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        if st.button("‚ñ∂Ô∏è Executar Pipeline"):
                            st.info(f"Executando pipeline: {selected_pipeline}")
                    with col2:
                        if st.button("‚è∏Ô∏è Pausar Pipeline"):
                            st.info(f"Pipeline pausado: {selected_pipeline}")
                    with col3:
                        if st.button("üìä Ver Logs"):
                            st.info(f"Mostrando logs de: {selected_pipeline}")
                else:
                    st.info("Nenhum pipeline registrado")
                    
            except Exception as e:
                st.error(f"Erro ao carregar pipelines: {e}")
        else:
            st.warning("Orchestrator n√£o dispon√≠vel")
    
    with tab4:
        st.subheader("Configura√ß√£o da Plataforma")
        
        if config_manager:
            try:
                # Mostrar configura√ß√µes atuais
                st.write("**Configura√ß√µes Atuais:**")
                
                # Configura√ß√µes de exemplo (adapte conforme necess√°rio)
                config_sections = ["platform", "services", "monitoring", "logging"]
                
                for section in config_sections:
                    with st.expander(f"üìã {section.title()}"):
                        try:
                            config = config_manager.get_config(section)
                            st.json(config)
                        except Exception as e:
                            st.warning(f"N√£o foi poss√≠vel carregar config de {section}: {e}")
                
                # Formul√°rio para atualizar configura√ß√µes
                st.write("**Atualizar Configura√ß√£o:**")
                with st.form("config_form"):
                    section = st.selectbox("Se√ß√£o", config_sections)
                    key = st.text_input("Chave")
                    value = st.text_input("Valor")
                    
                    if st.form_submit_button("Atualizar"):
                        try:
                            # config_manager.update_config(section, key, value)
                            st.success(f"Configura√ß√£o atualizada: {section}.{key} = {value}")
                        except Exception as e:
                            st.error(f"Erro ao atualizar configura√ß√£o: {e}")
                            
            except Exception as e:
                st.error(f"Erro ao carregar configura√ß√µes: {e}")
        else:
            st.warning("Gerenciador de configura√ß√£o n√£o dispon√≠vel")

elif page == "Configura√ß√£o":
    st.header("‚öôÔ∏è Configura√ß√£o do Sistema")
    
    st.write("**Configura√ß√µes Gerais:**")
    
    # Configura√ß√µes de refresh
    refresh_interval = st.slider("Intervalo de Refresh (segundos)", 30, 300, 60)
    st.write(f"Dados ser√£o atualizados a cada {refresh_interval} segundos")
    
    # Configura√ß√µes de logging
    log_level = st.selectbox("N√≠vel de Log", ["DEBUG", "INFO", "WARNING", "ERROR"])
    
    # Configura√ß√µes de notifica√ß√µes
    enable_notifications = st.checkbox("Habilitar Notifica√ß√µes", value=True)
    
    # Configura√ß√µes da plataforma unificada
    st.write("**Configura√ß√µes da Plataforma Unificada:**")
    
    if platform:
        st.success("‚úÖ Plataforma unificada est√° ativa")
        
        # Mostrar informa√ß√µes do sistema
        with st.expander("üìã Informa√ß√µes do Sistema"):
            system_info = {
                "Plataforma Ativa": True,
                "M√≥dulos Carregados": ["core.platform", "core.config", "core.orchestrator"],
                "Servi√ßos Registrados": len(platform.service_registry) if platform else 0,
                "Timestamp": datetime.now().isoformat()
            }
            st.json(system_info)
    else:
        st.warning("‚ö†Ô∏è Plataforma unificada n√£o est√° ativa")
        st.info("Para ativar a plataforma unificada:")
        st.code("""
# 1. Execute o setup
python setup.sh

# 2. Ou use o CLI
python datalab_cli.py platform start

# 3. Ou use o manager
python datalab_manager.py
        """)

# Rodap√©
st.markdown("---")
st.markdown("üöÄ DataLab Plataforma Unificada | Atualizado em: 9 de julho de 2025")
