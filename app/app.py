"""
Aplica√ß√£o Streamlit para visualiza√ß√£o e intera√ß√£o com o DataFlow Lab
"""

import json
import os
from datetime import datetime, timedelta

import pandas as pd
import plotly.express as px
import requests
import streamlit as st
from PIL import Image

# Configura√ß√£o da p√°gina
st.set_page_config(page_title="DataFlow Lab Dashboard", page_icon="üìä", layout="wide")

# T√≠tulo e descri√ß√£o
st.title("üîÑ DataFlow Lab - Dashboard")
st.markdown(
    """
    Painel de controle para monitoramento e intera√ß√£o com a plataforma DataFlow Lab.
    Este dashboard permite visualizar dados, monitorar pipelines e interagir com os servi√ßos.
"""
)

# Sidebar com navega√ß√£o
st.sidebar.title("Navega√ß√£o")
page = st.sidebar.radio(
    "Selecione uma p√°gina",
    ["Vis√£o Geral", "Camadas", "Pipelines", "Servi√ßos", "ML Models"],
)


# Status dos servi√ßos
@st.cache_data(ttl=60)  # Cache por 60 segundos
def check_service_status(url):
    try:
        response = requests.get(url, timeout=1)
        if response.status_code < 400:
            return "üü¢ Online"
        else:
            return "üü† Problema"
    except:
        return "üî¥ Offline"


# Fun√ß√µes para simular dados
@st.cache_data(ttl=300)  # Cache por 5 minutos
def get_sample_data():
    # Dados simulados para demonstra√ß√£o
    dates = pd.date_range(end=datetime.now(), periods=30).tolist()
    bronze_counts = [100 + i * 10 + int(i**1.5) for i in range(30)]
    silver_counts = [bronze_counts[i] * 0.8 for i in range(30)]
    gold_counts = [silver_counts[i] * 0.6 for i in range(30)]

    df = pd.DataFrame(
        {
            "date": dates,
            "bronze": bronze_counts,
            "silver": silver_counts,
            "gold": gold_counts,
        }
    )

    return df


@st.cache_data
def get_pipeline_data():
    # Dados simulados para demonstra√ß√£o de pipelines
    now = datetime.now()
    pipelines = [
        {
            "name": "ETL_Financial",
            "last_run": (now - timedelta(minutes=30)).strftime("%Y-%m-%d %H:%M:%S"),
            "status": "Sucesso",
            "duration": "5m 12s",
            "records": 15420,
        },
        {
            "name": "Stock_Data_Ingestion",
            "last_run": (now - timedelta(hours=2)).strftime("%Y-%m-%d %H:%M:%S"),
            "status": "Sucesso",
            "duration": "3m 45s",
            "records": 8750,
        },
        {
            "name": "Customer_Analytics",
            "last_run": (now - timedelta(hours=8)).strftime("%Y-%m-%d %H:%M:%S"),
            "status": "Falha",
            "duration": "2m 30s",
            "records": 0,
        },
        {
            "name": "Product_Metrics",
            "last_run": (now - timedelta(hours=12)).strftime("%Y-%m-%d %H:%M:%S"),
            "status": "Sucesso",
            "duration": "8m 20s",
            "records": 25300,
        },
        {
            "name": "ML_Training_Daily",
            "last_run": (now - timedelta(hours=24)).strftime("%Y-%m-%d %H:%M:%S"),
            "status": "Sucesso",
            "duration": "15m 45s",
            "records": 42680,
        },
    ]
    return pd.DataFrame(pipelines)


@st.cache_data
def get_model_data():
    # Dados simulados sobre modelos de ML
    models = [
        {
            "name": "price_prediction_v1",
            "type": "RandomForest",
            "accuracy": 0.87,
            "created": "2025-05-08",
            "status": "Production",
        },
        {
            "name": "customer_churn_v2",
            "type": "XGBoost",
            "accuracy": 0.92,
            "created": "2025-05-09",
            "status": "Staging",
        },
        {
            "name": "product_recommendation",
            "type": "Neural Network",
            "accuracy": 0.78,
            "created": "2025-05-10",
            "status": "Development",
        },
        {
            "name": "anomaly_detector_v1",
            "type": "Isolation Forest",
            "accuracy": 0.81,
            "created": "2025-05-07",
            "status": "Production",
        },
    ]
    return pd.DataFrame(models)


# P√°gina principal - Vis√£o Geral
if page == "Vis√£o Geral":
    st.header("Vis√£o Geral do DataFlow Lab")

    # Status dos servi√ßos em cards
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.info("**MinIO**")
        st.write(check_service_status("http://minio:9000"))
    with col2:
        st.info("**Spark**")
        st.write(check_service_status("http://spark-master:8080"))
    with col3:
        st.info("**MLflow**")
        st.write(check_service_status("http://mlflow:5000"))
    with col4:
        st.info("**Prefect**")
        st.write(check_service_status("http://prefect:4200"))

    # Gr√°fico de dados
    st.subheader("Volume de Dados por Camada")
    df = get_sample_data()

    chart = px.line(
        df,
        x="date",
        y=["bronze", "silver", "gold"],
        title="Evolu√ß√£o do Volume de Dados",
        labels={"value": "Registros", "date": "Data", "variable": "Camada"},
        color_discrete_map={
            "bronze": "#cd7f32",
            "silver": "#c0c0c0",
            "gold": "#ffd700",
        },
    )
    st.plotly_chart(chart, use_container_width=True)

    # √öltimos pipelines executados
    st.subheader("√öltimos Pipelines Executados")
    pipelines_df = get_pipeline_data()

    # Colorir o status
    def color_status(val):
        color = "green" if val == "Sucesso" else "red"
        return f"background-color: {color}; color: white"

    styled_df = pipelines_df.style.applymap(color_status, subset=["status"])

    st.dataframe(styled_df, use_container_width=True)

# P√°gina de camadas
elif page == "Camadas":
    st.header("Arquitetura Medallion")

    layer_tabs = st.tabs(["Bronze", "Silver", "Gold"])

    with layer_tabs[0]:
        st.subheader("Camada Bronze")
        st.markdown(
            """
        A camada Bronze cont√©m dados brutos ingeridos sem modifica√ß√µes ou com modifica√ß√µes m√≠nimas.
        Principais caracter√≠sticas:
        - Preserva os dados originais para auditoria e recupera√ß√£o
        - Inclui metadados como hora de ingest√£o e fonte
        - Armazenada em formato Delta Lake para garantias ACID
        """
        )

        st.info("**Tabelas na camada Bronze**")
        bronze_tables = [
            "raw_financial_data",
            "raw_stock_data",
            "raw_customer_data",
            "raw_logs",
        ]
        for table in bronze_tables:
            st.code(f"s3a://bronze/{table}")

    with layer_tabs[1]:
        st.subheader("Camada Silver")
        st.markdown(
            """
        A camada Silver cont√©m dados limpos, validados e transformados.
        Principais caracter√≠sticas:
        - Dados normalizados e estruturados
        - Valores nulos tratados e anomalias removidas
        - Esquema consistente e documentado
        """
        )

        st.info("**Tabelas na camada Silver**")
        silver_tables = [
            "clean_financial_data",
            "clean_stock_data",
            "clean_customer_data",
        ]
        for table in silver_tables:
            st.code(f"s3a://silver/{table}")

    with layer_tabs[2]:
        st.subheader("Camada Gold")
        st.markdown(
            """
        A camada Gold cont√©m dados refinados e agregados para consumo.
        Principais caracter√≠sticas:
        - Tabelas e views preparadas para an√°lise
        - Dados agregados e modelados para casos de uso espec√≠ficos
        - Otimizados para consulta e an√°lise
        """
        )

        st.info("**Tabelas na camada Gold**")
        gold_tables = [
            "financial_metrics",
            "stock_analysis",
            "customer_segments",
            "dashboards",
        ]
        for table in gold_tables:
            st.code(f"s3a://gold/{table}")

# P√°gina de Pipelines
elif page == "Pipelines":
    st.header("Pipelines de Dados")
    st.markdown(
        """
    Aqui voc√™ pode monitorar e gerenciar os pipelines de dados da plataforma.
    Os pipelines s√£o orquestrados com Prefect e processam dados atrav√©s das camadas.
    """
    )

    # Formul√°rio para criar um novo pipeline
    with st.expander("Criar Novo Pipeline"):
        with st.form("new_pipeline_form"):
            st.subheader("Novo Pipeline")
            name = st.text_input("Nome do Pipeline")
            source_type = st.selectbox(
                "Tipo de Fonte",
                ["PostgreSQL", "MySQL", "API", "CSV", "Parquet", "JSON"],
            )
            target_table = st.text_input("Tabela de Destino")
            schedule = st.selectbox(
                "Agendamento", ["Di√°rio", "Hor√°rio", "Semanal", "Mensal", "Manual"]
            )

            # Adicionar bot√£o para enviar
            submitted = st.form_submit_button("Criar Pipeline")
            if submitted:
                st.success(f"Pipeline '{name}' criado com sucesso!")

    # Lista de pipelines
    st.subheader("Pipelines Ativos")
    pipelines_df = get_pipeline_data()

    # Filtros
    status_filter = st.selectbox("Filtrar por Status", ["Todos", "Sucesso", "Falha"])
    if status_filter != "Todos":
        pipelines_df = pipelines_df[pipelines_df["status"] == status_filter]

    # Mostrar tabela
    st.dataframe(pipelines_df, use_container_width=True)

    # Detalhes do pipeline
    st.subheader("Detalhes do Pipeline")
    selected_pipeline = st.selectbox(
        "Selecione um pipeline para ver detalhes", pipelines_df["name"].tolist()
    )

    # Bot√µes de a√ß√£o
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("Executar Agora"):
            st.info(f"Executando pipeline {selected_pipeline}...")
            st.success(f"Pipeline {selected_pipeline} iniciado com sucesso!")
    with col2:
        st.button("Editar Pipeline")
    with col3:
        st.button("Pausar Pipeline")

    # Mostrar logs simulados
    st.subheader("Logs do Pipeline")
    st.code(
        f"""
    [2025-05-11 08:30:15] INFO: Pipeline {selected_pipeline} iniciado
    [2025-05-11 08:30:18] INFO: Conectando √† fonte de dados
    [2025-05-11 08:30:25] INFO: Dados extra√≠dos com sucesso (12345 registros)
    [2025-05-11 08:31:05] INFO: Dados transformados
    [2025-05-11 08:32:10] INFO: Dados carregados na camada destino
    [2025-05-11 08:32:15] INFO: Pipeline conclu√≠do com sucesso
    """
    )

# P√°gina de Servi√ßos
elif page == "Servi√ßos":
    st.header("Servi√ßos da Plataforma")
    st.markdown(
        """
    Aqui voc√™ pode monitorar e acessar os diversos servi√ßos que comp√µem a plataforma DataFlow Lab.
    """
    )

    # Cart√µes para os servi√ßos com links
    col1, col2 = st.columns(2)

    with col1:
        st.info("### MinIO")
        st.write("Sistema de armazenamento de objetos compat√≠vel com S3")
        st.write("- Console: [http://localhost:9001](http://localhost:9001)")
        st.write("- Status: ", check_service_status("http://minio:9000"))
        if st.button("Inicializar Buckets"):
            st.success("Buckets bronze, silver e gold criados com sucesso!")

    with col2:
        st.info("### Apache Spark")
        st.write("Framework de processamento distribu√≠do")
        st.write("- UI: [http://localhost:8080](http://localhost:8080)")
        st.write("- Status: ", check_service_status("http://spark-master:8080"))
        if st.button("Ver Aplica√ß√µes Ativas"):
            st.code(
                """
            ApplicationID: spark-20250511123456-0001
            Nome: medallion_example
            Estado: RUNNING
            Cores: 2
            Mem√≥ria: 2.0 GB
            """
            )

    col3, col4 = st.columns(2)

    with col3:
        st.info("### MLflow")
        st.write("Plataforma para gerenciamento do ciclo de vida de ML")
        st.write("- UI: [http://localhost:5000](http://localhost:5000)")
        st.write("- Status: ", check_service_status("http://mlflow:5000"))
        if st.button("Ver Experimentos"):
            st.dataframe(
                {
                    "ID": [1, 2, 3],
                    "Nome": ["price_prediction", "customer_churn", "anomaly_detection"],
                    "Execu√ß√µes": [15, 8, 23],
                }
            )

    with col4:
        st.info("### Prefect")
        st.write("Orquestrador de fluxos de dados")
        st.write("- UI: [http://localhost:4200](http://localhost:4200)")
        st.write("- Status: ", check_service_status("http://prefect:4200"))
        if st.button("Ver Fluxos"):
            st.dataframe(
                {
                    "Nome": ["medallion_pipeline", "etl_di√°rio", "treinamento_ml"],
                    "Estado": ["Healthy", "Healthy", "Warning"],
                    "√öltima Execu√ß√£o": [
                        "11/05/2025 08:30",
                        "11/05/2025 04:00",
                        "10/05/2025 22:00",
                    ],
                }
            )

# P√°gina de ML Models
elif page == "ML Models":
    st.header("Machine Learning Models")
    st.markdown(
        """
    Aqui voc√™ pode monitorar e gerenciar os modelos de Machine Learning da plataforma.
    Os modelos s√£o treinados com dados da camada Gold e rastreados com MLflow.
    """
    )

    # Lista de modelos
    models_df = get_model_data()

    # Filtros
    model_status = st.selectbox(
        "Filtrar por Status", ["Todos", "Production", "Staging", "Development"]
    )
    if model_status != "Todos":
        models_df = models_df[models_df["status"] == model_status]

    # Mostrar tabela
    st.dataframe(models_df, use_container_width=True)

    # Gr√°fico de barras para acur√°cia
    fig = px.bar(
        models_df,
        x="name",
        y="accuracy",
        color="type",
        title="Acur√°cia dos Modelos",
        labels={"name": "Nome do Modelo", "accuracy": "Acur√°cia", "type": "Tipo"},
    )
    st.plotly_chart(fig, use_container_width=True)

    # Formul√°rio para treinar novo modelo
    with st.expander("Treinar Novo Modelo"):
        with st.form("train_model_form"):
            st.subheader("Novo Modelo")
            name = st.text_input("Nome do Modelo")
            model_type = st.selectbox(
                "Tipo de Modelo",
                [
                    "RandomForest",
                    "XGBoost",
                    "Neural Network",
                    "Linear Regression",
                    "Isolation Forest",
                ],
            )
            dataset = st.selectbox(
                "Dataset de Treinamento",
                [
                    "gold.financial_metrics",
                    "gold.customer_segments",
                    "gold.stock_analysis",
                ],
            )
            target = st.text_input("Vari√°vel Alvo")

            # Adicionar bot√£o para enviar
            submitted = st.form_submit_button("Treinar Modelo")
            if submitted:
                st.success(f"Treinamento do modelo '{name}' iniciado!")

    # Bot√£o para implementar modelo em produ√ß√£o
    selected_model = st.selectbox(
        "Selecione um modelo para a√ß√£o", models_df["name"].tolist()
    )

    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("Promover para Produ√ß√£o"):
            st.success(f"Modelo {selected_model} promovido para produ√ß√£o!")
    with col2:
        st.button("Ver M√©tricas Detalhadas")
    with col3:
        st.button("Baixar Modelo")

# Rodap√©
st.markdown("---")
st.markdown("DataFlow Lab Dashboard | Atualizado em: 11 de maio de 2025")
