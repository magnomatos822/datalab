# DataFlow Lab

<div align="center">
  <img src="https://img.shields.io/badge/Apache_Spark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white" alt="Apache Spark">
  <img src="https://img.shields.io/badge/MLflow-0194E2?style=for-the-badge&logo=mlflow&logoColor=white" alt="MLflow">
  <img src="https://img.shields.io/badge/Prefect-024DFD?style=for-the-badge&logo=prefect&logoColor=white" alt="Prefect">
  <img src="https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white" alt="Jupyter">
  <img src="https://img.shields.io/badge/MinIO-C72E49?style=for-the-badge&logo=minio&logoColor=white" alt="MinIO">
  <img src="https://img.shields.io/badge/Delta_Lake-00ADD8?style=for-the-badge&logo=delta&logoColor=white" alt="Delta Lake">
  <img src="https://img.shields.io/badge/Airbyte-615EFF?style=for-the-badge&logo=airbyte&logoColor=white" alt="Airbyte">
</div>

<br>

> Arquitetura moderna de Data Lakehouse com pipeline de dados para engenharia de dados e machine learning â€” processamento em camadas (Bronze, Silver, Gold), garantias ACID, time travel, monitoramento e orquestraÃ§Ã£o.

## ğŸ“‹ SumÃ¡rio

- [DataFlow Lab](#dataflow-lab)
  - [ğŸ“‹ SumÃ¡rio](#-sumÃ¡rio)
  - [ğŸ”­ VisÃ£o Geral](#-visÃ£o-geral)
  - [ğŸ—ï¸ Arquitetura](#ï¸-arquitetura)
  - [ğŸ§© Componentes](#-componentes)
    - [Armazenamento de Dados](#armazenamento-de-dados)
    - [IngestÃ£o e ETL](#ingestÃ£o-e-etl)
    - [Processamento de Dados](#processamento-de-dados)
    - [Machine Learning](#machine-learning)
    - [OrquestraÃ§Ã£o](#orquestraÃ§Ã£o)
    - [Desenvolvimento](#desenvolvimento)
    - [VisualizaÃ§Ã£o](#visualizaÃ§Ã£o)
  - [ğŸš€ InÃ­cio RÃ¡pido](#-inÃ­cio-rÃ¡pido)
    - [PrÃ©-requisitos](#prÃ©-requisitos)
    - [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
  - [ğŸ“‚ Estrutura do Projeto](#-estrutura-do-projeto)
  - [ğŸ”„ IntegraÃ§Ã£o com Airbyte](#-integraÃ§Ã£o-com-airbyte)
  - [ğŸ“ˆ Analytics com Spark](#-analytics-com-spark)
  - [ğŸ‘¥ ContribuiÃ§Ã£o](#-contribuiÃ§Ã£o)
  - [ğŸ“„ LicenÃ§a](#-licenÃ§a)

## ğŸ”­ VisÃ£o Geral

O DataFlow Lab Ã© uma plataforma completa de Data Lakehouse para processamento de dados, abrangendo desde a ingestÃ£o de dados brutos atÃ© a criaÃ§Ã£o de modelos de machine learning. A arquitetura implementa prÃ¡ticas modernas de engenharia de dados como processamento em camadas (Medallion: Bronze, Silver, Gold), transaÃ§Ãµes ACID atravÃ©s do Delta Lake, rastreabilidade e reprodutibilidade.

Atualizado em: **12 de maio de 2025**

## ğŸ—ï¸ Arquitetura

<pre>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          â”‚     â”‚          â”‚     â”‚          â”‚     â”‚          â”‚     â”‚            â”‚
â”‚   RAW    â”‚â”€â”€â”€â”€â–¶â”‚  BRONZE  â”‚â”€â”€â”€â”€â–¶â”‚  SILVER  â”‚â”€â”€â”€â”€â–¶â”‚   GOLD   â”‚â”€â”€â”€â”€â–¶â”‚  ML MODELS â”‚
â”‚   DATA   â”‚     â”‚  LAYER   â”‚     â”‚  LAYER   â”‚     â”‚  LAYER   â”‚     â”‚            â”‚
â”‚          â”‚     â”‚          â”‚     â”‚          â”‚     â”‚          â”‚     â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                â”‚                â”‚                â”‚                 â”‚
      â”‚                â”‚                â”‚                â”‚                 â”‚
      â–¼                â–¼                â–¼                â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                              â”‚
â”‚                          ACID TRANSACTIONS (Delta Lake)                      â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                â”‚                â”‚                â”‚                 â”‚
      â”‚                â”‚                â”‚                â”‚                 â”‚
      â–¼                â–¼                â–¼                â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                              â”‚
â”‚                              DATA GOVERNANCE                                 â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                â”‚                â”‚                â”‚                 â”‚
      â”‚                â”‚                â”‚                â”‚                 â”‚
      â–¼                â–¼                â–¼                â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                              â”‚
â”‚                          WORKFLOW ORCHESTRATION                              â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</pre>

## ğŸ§© Componentes

O sistema Ã© composto por vÃ¡rios componentes integrados que formam uma plataforma completa de Data Lakehouse:

### Armazenamento de Dados
- **[MinIO](docs/minio/README.md)**: Sistema de armazenamento de objetos compatÃ­vel com Amazon S3
  - Console: [http://localhost:9001](http://localhost:9001) (admin/admin123)
  - API: [http://localhost:9000](http://localhost:9000)
  - Buckets: bronze, silver, gold (arquitetura Medallion)

### IngestÃ£o e ETL
- **[Airbyte](docs/airbyte/README.md)**: Plataforma de integraÃ§Ã£o de dados de cÃ³digo aberto
  - UI: [http://localhost:8000](http://localhost:8000) (airbyte/password)
  - Conectores para mais de 300 fontes de dados

### Processamento de Dados
- **[Apache Spark](docs/spark/README.md)**: Framework de processamento distribuÃ­do
  - Master UI: [http://localhost:8080](http://localhost:8080)
  - Worker UI: [http://localhost:8081](http://localhost:8081)
- **[Delta Lake](docs/spark/README.md#delta-lake)**: Camada de armazenamento que traz transaÃ§Ãµes ACID para Spark
  - Formatos: delta (com garantias ACID)
  - Recursos: Time Travel, MERGE, Z-Order, Optimize

### Machine Learning
- **[MLflow](docs/mlflow/README.md)**: Plataforma para gerenciamento do ciclo de vida de ML
  - UI: [http://localhost:5000](http://localhost:5000)
  - Tracking, registros de modelos e serviÃ§o

### OrquestraÃ§Ã£o
- **[Prefect](docs/prefect/README.md)**: Orquestrador de fluxos de dados
  - UI: [http://localhost:4200](http://localhost:4200)
  - Fluxos, tarefas e monitoramento

### Desenvolvimento
- **[JupyterHub](docs/jupyter/README.md)**: Ambiente de desenvolvimento interativo multi-usuÃ¡rio
  - UI: [http://localhost:8888](http://localhost:8888)
  - Notebooks para anÃ¡lise exploratÃ³ria

### VisualizaÃ§Ã£o
- **[Streamlit](docs/streamlit/README.md)**: Framework para criaÃ§Ã£o de aplicaÃ§Ãµes de dados
  - UI: [http://localhost:8501](http://localhost:8501)
  - Dashboards interativos

## ğŸš€ InÃ­cio RÃ¡pido

### PrÃ©-requisitos

- Docker e Docker Compose instalados
- Git (opcional, para clonar o repositÃ³rio)
- Recomendado: 8GB+ de RAM e 20GB+ de espaÃ§o em disco

### InstalaÃ§Ã£o

1. Clone o repositÃ³rio (ou baixe como ZIP):
   ```bash
   git clone https://github.com/seu-usuario/dataflow-lab.git
   cd dataflow-lab
   ```

2. Inicie os serviÃ§os:
   ```bash
   docker-compose up -d
   ```

3. Verifique se todos os serviÃ§os estÃ£o rodando:
   ```bash
   docker-compose ps
   ```

   Para verificar os logs de um serviÃ§o especÃ­fico (por exemplo, Spark):
   ```bash
   docker-compose logs spark-master
   ```
   docker-compose ps
   ```

### URLs dos ServiÃ§os

| ServiÃ§o      | URL                   | Credenciais      |
| ------------ | --------------------- | ---------------- |
| MinIO        | http://localhost:9001 | admin/admin123   |
| Airbyte      | http://localhost:8000 | airbyte/password |
| Spark Master | http://localhost:8080 | -                |
| MLflow       | http://localhost:5000 | -                |
| Prefect UI   | http://localhost:4200 | -                |
| JupyterHub   | http://localhost:8888 | (token nos logs) |
| Streamlit    | http://localhost:8501 | -                |

## ğŸ“Š Uso do Sistema

### Arquitetura Medallion

Nossa implementaÃ§Ã£o segue a arquitetura Medallion (tambÃ©m conhecida como multi-hop), organizada em trÃªs camadas principais:

1. **Bronze**: Dados brutos ingeridos sem modificaÃ§Ãµes ou com mÃ­nimas transformaÃ§Ãµes
   - Preserva os dados originais para auditoria e recuperaÃ§Ã£o
   - Inclui metadados como hora de ingestÃ£o e fonte

2. **Silver**: Dados limpos, validados e transformados
   - Dados normalizados e estruturados
   - Valores nulos tratados e anomalias removidas
   - Esquema consistente e documentado

3. **Gold**: Dados refinados e agregados para consumo
   - Tabelas e views preparadas para anÃ¡lise
   - Dados agregados e modelados para casos de uso especÃ­ficos
   - Otimizados para consulta e anÃ¡lise

### TransaÃ§Ãµes ACID com Delta Lake

O projeto implementa o Delta Lake para fornecer garantias ACID (Atomicidade, ConsistÃªncia, Isolamento, Durabilidade):

- **AtualizaÃ§Ãµes incrementais (MERGE)**: Capacidade de atualizar registros existentes e inserir novos em uma Ãºnica operaÃ§Ã£o atÃ´mica
- **Time Travel**: Acesso a versÃµes anteriores dos dados usando versÃ£o especÃ­fica ou timestamp
- **OtimizaÃ§Ã£o de tabelas**: CompactaÃ§Ã£o de arquivos pequenos e Z-Order para melhor performance de consulta
- **Schema Enforcement**: ValidaÃ§Ã£o automÃ¡tica de esquema para garantir qualidade dos dados
- **Gerenciamento de histÃ³rico**: Controle sobre retenÃ§Ã£o de versÃµes antigas para economia de espaÃ§o

### Fluxo de Dados TÃ­pico

1. **IngestÃ£o de Dados**: Coleta de dados de fontes diversas (APIs, bancos de dados, arquivos) usando Airbyte ou mÃ©todos personalizados
2. **Armazenamento Bronze**: Armazenamento dos dados brutos no formato Delta Lake (MinIO)
3. **Processamento Silver**: Limpeza e transformaÃ§Ã£o com Apache Spark
4. **Refinamento Gold**: AgregaÃ§Ãµes e modelagem para anÃ¡lise
5. **Modelagem**: Treinamento de modelos preditivos com rastreamento no MLflow
6. **OrquestraÃ§Ã£o**: AutomatizaÃ§Ã£o e agendamento de pipelines com Prefect
7. **VisualizaÃ§Ã£o**: Dashboards e aplicaÃ§Ãµes com Streamlit

### Casos de Uso

O DataFlow Lab foi projetado para suportar diversos casos de uso:

- **ETL e ELT modernos**: Processamento de dados com estrutura de medallion
- **Machine Learning**: Treinamento e implementaÃ§Ã£o de modelos com MLflow
- **AnÃ¡lise financeira**: Processamento de sÃ©ries temporais e dados financeiros
- **Processamento de logs**: AnÃ¡lise de logs e telemetria
- **IntegraÃ§Ã£o de dados**: UnificaÃ§Ã£o de fontes de dados heterogÃªneas
- **Analytics em tempo real**: Processamento de streaming com Spark Structured Streaming

### Exemplos PrÃ¡ticos

Consulte nossos exemplos para casos de uso comuns:

- `/app/medallion_example.py`: Exemplo completo da arquitetura Medallion com Delta Lake
- `/app/medallion_prefect_flow.py`: OrquestraÃ§Ã£o do pipeline Medallion usando Prefect
- `/app/analytics.py`: AnÃ¡lises avanÃ§adas com Apache Spark
- `/notebooks/magnomatos822/amazon.ipynb`: AnÃ¡lise de dados financeiros da Amazon

Para executar o exemplo da arquitetura Medallion:

```bash
docker exec -it spark-master python /spark-apps/medallion_prefect_flow.py
```

## ğŸ“‚ Estrutura do Projeto

```
dataflow-lab/
â”‚
â”œâ”€â”€ docker-compose.yml      # DefiniÃ§Ã£o dos serviÃ§os Docker
â”œâ”€â”€ jupyterhub_config.py    # ConfiguraÃ§Ã£o do JupyterHub
â”œâ”€â”€ README.md               # Este arquivo
â”œâ”€â”€ LICENSE                 # LicenÃ§a do projeto
â”œâ”€â”€ requirements.txt        # DependÃªncias Python (incluindo delta-spark)
â”‚
â”œâ”€â”€ app/                    # CÃ³digo Python da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ airbyte_integration.py     # IntegraÃ§Ã£o com Airbyte
â”‚   â”œâ”€â”€ airbyte_monitoring.py      # Monitoramento de conexÃµes Airbyte
â”‚   â”œâ”€â”€ airbyte_prefect_deployment.py  # IntegraÃ§Ã£o Airbyte + Prefect
â”‚   â”œâ”€â”€ analytics.py               # FunÃ§Ãµes analÃ­ticas com Spark
â”‚   â”œâ”€â”€ app.py                     # AplicaÃ§Ã£o principal
â”‚   â”œâ”€â”€ ingestion.py               # MÃ³dulo de ingestÃ£o de dados
â”‚   â”œâ”€â”€ medallion_architecture.py  # ImplementaÃ§Ã£o da arquitetura Medallion
â”‚   â”œâ”€â”€ medallion_example.py       # Exemplo de uso
â”‚   â”œâ”€â”€ medallion_prefect_flow.py  # Fluxos Prefect para orquestraÃ§Ã£o
â”‚   â””â”€â”€ processor.py               # Processamento de dados com Spark
â”‚
â”œâ”€â”€ docs/                   # DocumentaÃ§Ã£o detalhada
â”‚   â”œâ”€â”€ airbyte/            # DocumentaÃ§Ã£o do Airbyte
â”‚   â”œâ”€â”€ minio/              # DocumentaÃ§Ã£o do MinIO
â”‚   â”œâ”€â”€ spark/              # DocumentaÃ§Ã£o do Apache Spark e Delta Lake
â”‚   â”œâ”€â”€ mlflow/             # DocumentaÃ§Ã£o do MLflow
â”‚   â”œâ”€â”€ prefect/            # DocumentaÃ§Ã£o do Prefect
â”‚   â””â”€â”€ jupyter/            # DocumentaÃ§Ã£o do Jupyter
â”‚
â”œâ”€â”€ notebooks/              # Jupyter notebooks de exemplo
â”‚   â”œâ”€â”€ magnomatos822/      # Notebooks do usuÃ¡rio
â”‚   â”‚   â”œâ”€â”€ amazon.ipynb    # AnÃ¡lise de dados da Amazon
â”‚   â”‚   â””â”€â”€ teste.ipynb     # Notebook de testes
â”‚   â””â”€â”€ tutorials/          # Notebooks de tutoriais
â”‚
â”œâ”€â”€ config/                 # Arquivos de configuraÃ§Ã£o
â”‚   â”œâ”€â”€ minio/              # ConfiguraÃ§Ãµes do MinIO
â”‚   â”œâ”€â”€ spark/              # ConfiguraÃ§Ãµes do Spark
â”‚   â””â”€â”€ nginx/              # ConfiguraÃ§Ãµes do NGINX
â”‚
â”œâ”€â”€ data/                   # DiretÃ³rio para armazenar dados
â”‚   â”œâ”€â”€ jupyter/            # Dados do JupyterHub
â”‚   â”œâ”€â”€ minio/              # Buckets do MinIO (bronze, silver, gold)
â”‚   â”œâ”€â”€ mlflow/             # Dados do MLflow
â”‚   â”œâ”€â”€ prefect/            # Dados do Prefect
â”‚   â”œâ”€â”€ spark/              # Logs e dados do Spark
â”‚   â””â”€â”€ streamlit/          # Dados do Streamlit
â”‚
â”œâ”€â”€ flows/                  # DefiniÃ§Ãµes de fluxos Prefect
â”œâ”€â”€ mlruns/                 # DiretÃ³rio para armazenar artefatos do MLflow
â”‚   â””â”€â”€ models/             # Modelos treinados
â”‚
â””â”€â”€ models/                 # Modelos exportados
```

## ğŸ”„ IntegraÃ§Ã£o com Airbyte

O DataFlow Lab integra-se com o Airbyte para ingestÃ£o de dados de diversas fontes. Os principais componentes de integraÃ§Ã£o sÃ£o:

- **airbyte_integration.py**: Fornece APIs para interagir com o Airbyte
- **airbyte_monitoring.py**: Monitora o status das conexÃµes e sincronizaÃ§Ãµes
- **airbyte_prefect_deployment.py**: Integra fluxos de dados do Airbyte com orquestraÃ§Ã£o Prefect

Para configurar uma nova fonte de dados:

1. Acesse a UI do Airbyte em http://localhost:8000
2. Configure a fonte de dados desejada
3. Configure o destino como MinIO (Bronze layer)
4. Crie uma conexÃ£o entre fonte e destino
5. Use os scripts de integraÃ§Ã£o para automatizar o processo

## ğŸ“ˆ Analytics com Spark

O componente de analytics (`app/analytics.py`) fornece funÃ§Ãµes para anÃ¡lise de dados avanÃ§ada:

- AnÃ¡lise de sÃ©ries temporais
- DetecÃ§Ã£o de anomalias
- AnÃ¡lise de sentimento
- Processamento de linguagem natural
- AnÃ¡lises preditivas

Exemplo de uso:

```python
from app.analytics import TimeSeriesAnalyzer

# Carregar dados da camada Gold
data = spark.read.format("delta").load("s3a://gold/stock_data")

# Realizar anÃ¡lise de sÃ©ries temporais
analyzer = TimeSeriesAnalyzer(data)
results = analyzer.analyze(metric="close_price", period=30)
forecast = analyzer.forecast(days=7)
```

## ğŸ‘¥ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor, siga estas etapas para contribuir:

1. Fork o repositÃ³rio
2. Crie um branch para sua feature (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas alteraÃ§Ãµes (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push para o branch (`git push origin feature/nova-funcionalidade`)
5. Crie um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto Ã© licenciado sob a [GNU General Public License v3.0](LICENSE) - veja o arquivo LICENSE para detalhes.
