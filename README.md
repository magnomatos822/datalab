# DataFlow Lab

<div align="center">
  <img src="https://img.shields.io/badge/Apache_Spark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white" alt="Apache Spark">
  <img src="https://img.shields.io/badge/Delta_Lake-00ADD8?style=for-the-badge&logo=delta&logoColor=white" alt="Delta Lake">
  <img src="https://img.shields.io/badge/MLflow-0194E2?style=for-the-badge&logo=mlflow&logoColor=white" alt="MLflow">
  <img src="https://img.shields.io/badge/MinIO-C72E49?style=for-the-badge&logo=minio&logoColor=white" alt="MinIO">
  <img src="https://img.shields.io/badge/Prefect-2EBDFA?style=for-the-badge&logo=prefect&logoColor=white" alt="Prefect">
  <img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white" alt="Streamlit">
  <img src="https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white" alt="JupyterHub">
  <img src="https://img.shields.io/badge/Kafka-231F20?style=for-the-badge&logo=apache-kafka&logoColor=white" alt="Apache Kafka">
  <img src="https://img.shields.io/static/v1?style=for-the-badge&message=Apache+NiFi&color=728E9B&logo=Apache+NiFi&logoColor=FFFFFF&label=" alt="Apache NiFi">
</div>

> √öltima atualiza√ß√£o: 14 de maio de 2025

## üîç Vis√£o Geral

DataFlow Lab √© um ambiente completo de desenvolvimento para engenharia de dados, ci√™ncia de dados e MLOps que integra as melhores ferramentas open source em uma √∫nica plataforma. O projeto implementa a arquitetura Medallion (Bronze, Silver, Gold) oferecendo um ambiente completo para processamento de dados em larga escala.

## ‚ú® Caracter√≠sticas Principais

- **Arquitetura Medallion**: Implementa√ß√£o completa das camadas Bronze, Silver e Gold
- **Processamento Distribu√≠do**: Apache Spark para processamento em larga escala
- **Armazenamento Resiliente**: Delta Lake para gerenciamento de dados confi√°vel
- **Machine Learning**: MLflow para tracking, registro e deployment de modelos
- **Orquestra√ß√£o**: Prefect para orquestra√ß√£o de fluxos de dados
- **Ingest√£o de Dados**: Apache NiFi para automatizar a ingest√£o de v√°rias fontes
- **Streaming**: Apache Kafka para processamento de streaming em tempo real
- **Visualiza√ß√£o**: Streamlit para dashboards e aplica√ß√µes de dados interativas
- **Ambiente de Desenvolvimento**: JupyterHub para colabora√ß√£o e experimenta√ß√£o

## üìã Componentes

| Componente       | Vers√£o                       | Porta       | Descri√ß√£o                              | Documenta√ß√£o                               |
| ---------------- | ---------------------------- | ----------- | -------------------------------------- | ------------------------------------------ |
| **Apache Spark** | 3.5.1                        | 8080, 7077  | Processamento distribu√≠do de dados     | [Documenta√ß√£o](/docs/spark/README.md)      |
| **Delta Lake**   | 3.3.1                        | -           | Camada de armazenamento para lakehouse | [Documenta√ß√£o](/docs/spark/README.md)      |
| **MLflow**       | 2.22.0                       | 5000        | Plataforma de MLOps                    | [Documenta√ß√£o](/docs/mlflow/README.md)     |
| **MinIO**        | RELEASE.2025-04-22T22-12-26Z | 9000, 9001  | Armazenamento de objetos S3            | [Documenta√ß√£o](/docs/minio/README.md)      |
| **Prefect**      | 3.4.1                        | 4200        | Orquestra√ß√£o de fluxos                 | [Documenta√ß√£o](/docs/prefect/README.md)    |
| **Streamlit**    | 1.45.0                       | 8501        | Dashboards interativos                 | [Documenta√ß√£o](/docs/streamlit/README.md)  |
| **JupyterHub**   | 4.0.2                        | 8000        | Ambiente de desenvolvimento            | [Documenta√ß√£o](/docs/jupyterhub/README.md) |
| **Apache Kafka** | 7.5.0                        | 9092, 29092 | Streaming de eventos                   | [Documenta√ß√£o](/docs/kafka/README.md)      |
| **Apache NiFi**  | 2.4.0                        | 8443        | Automa√ß√£o de fluxo de dados            | [Documenta√ß√£o](/docs/nifi/README.md)       |

## üèóÔ∏è Arquitetura

A arquitetura do DataFlow Lab √© baseada no padr√£o Medallion (Lakehouse), organizada em tr√™s camadas principais:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          CAMADA DE INGEST√ÉO                         ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Apache  ‚îÇ    ‚îÇ  Apache   ‚îÇ    ‚îÇ  APIs/ ‚îÇ    ‚îÇ     Outros     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   NiFi   ‚îÇ    ‚îÇ   Kafka   ‚îÇ    ‚îÇ  REST  ‚îÇ    ‚îÇ    Coletores   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ       ‚îÇ                ‚îÇ               ‚îÇ                 ‚îÇ          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                ‚îÇ               ‚îÇ                 ‚îÇ
        ‚ñº                ‚ñº               ‚ñº                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ
‚îÇ                   ‚îÇ       BRONZE LAYER      ‚îÇ                       ‚îÇ
‚îÇ                   ‚îÇ    (Dados Brutos em     ‚îÇ                       ‚îÇ
‚îÇ                   ‚îÇ     Formato Delta)      ‚îÇ                       ‚îÇ
‚îÇ                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
‚îÇ                                ‚îÇ                                    ‚îÇ
‚îÇ                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ
‚îÇ                   ‚îÇ       SILVER LAYER      ‚îÇ                       ‚îÇ
‚îÇ                   ‚îÇ   (Dados Limpos com     ‚îÇ                       ‚îÇ
‚îÇ                   ‚îÇ  Qualidade Garantida)   ‚îÇ                       ‚îÇ
‚îÇ                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
‚îÇ                                ‚îÇ                                    ‚îÇ
‚îÇ                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ
‚îÇ                   ‚îÇ        GOLD LAYER       ‚îÇ                       ‚îÇ
‚îÇ                   ‚îÇ  (Dados Agregados para  ‚îÇ                       ‚îÇ
‚îÇ                   ‚îÇ        Consumo)         ‚îÇ                       ‚îÇ
‚îÇ                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
‚îÇ                             MINIO                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                ‚îÇ               ‚îÇ                 ‚îÇ
        ‚ñº                ‚ñº               ‚ñº                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          CAMADA DE CONSUMO                          ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇStreamlit ‚îÇ    ‚îÇ  MLflow   ‚îÇ    ‚îÇ Apache ‚îÇ    ‚îÇ    Outros      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇDashboards‚îÇ    ‚îÇ  Models   ‚îÇ    ‚îÇ Spark  ‚îÇ    ‚îÇ  Consumidores  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

A arquitetura Medallion possui tr√™s camadas principais:

1. **Bronze**: Dados brutos ingeridos exatamente como foram recebidos
2. **Silver**: Dados limpos, validados e transformados
3. **Gold**: Dados agregados e preparados para consumo por aplica√ß√µes

## üöÄ Como Come√ßar

### Pr√©-requisitos

- Docker
- Docker Compose
- Git

### Instala√ß√£o e Inicializa√ß√£o

1. Clone o reposit√≥rio:
   ```bash
   git clone https://github.com/seuusuario/datalab.git
   cd datalab
   ```

2. Inicie os servi√ßos:
   ```bash
   docker-compose up -d
   ```

3. Acesse os componentes pelos seguintes URLs (ap√≥s alguns minutos para inicializa√ß√£o):
   - JupyterHub: [http://localhost:8000](http://localhost:8000) (admin/admin)
   - MinIO Console: [http://localhost:9001](http://localhost:9001) (admin/admin123)
   - Apache Spark UI: [http://localhost:8080](http://localhost:8080)
   - MLflow UI: [http://localhost:5000](http://localhost:5000)
   - Prefect UI: [http://localhost:4200](http://localhost:4200)
   - Streamlit: [http://localhost:8501](http://localhost:8501)
   - Apache NiFi: [https://localhost:8443/nifi](https://localhost:8443/nifi) (nifi/HGd15bvfv8744ghbdhgdv7895agqERAo)
   - Kafka UI: [http://localhost:8090](http://localhost:8090)

### Inicializando os Buckets MinIO

Os buckets do MinIO s√£o inicializados automaticamente na primeira execu√ß√£o. Se necess√°rio, voc√™ pode inicializ√°-los manualmente:

```bash
./scripts/init_minio.sh
```

## üìö Tutoriais e Exemplos

### JupyterHub

O JupyterHub cont√©m v√°rios notebooks de exemplo para ajud√°-lo a come√ßar:

1. Autentique-se em [http://localhost:8000](http://localhost:8000) com as credenciais `admin`/`admin`
2. Navegue at√© a pasta `examples/` para ver os notebooks de exemplo
3. Comece com o notebook `medallion_architecture.ipynb` para uma vis√£o geral da arquitetura

### Exemplos de Arquitetura Medallion

- **Ingest√£o para Bronze**: Consulte o notebook `examples/bronze_ingestion.ipynb`
- **Processamento Bronze para Silver**: Consulte o notebook `examples/silver_processing.ipynb`
- **Agrega√ß√µes Silver para Gold**: Consulte o notebook `examples/gold_aggregations.ipynb`

## üìã Casos de Uso Comuns

### 1. Processamento de Dados Completo

```python
# No JupyterHub, usando PySpark com Delta Lake
from pyspark.sql import SparkSession
from pyspark.sql.functions import *

# Inicializa√ß√£o do Spark com suporte a Delta
spark = SparkSession.builder \
    .appName("MedallionExample") \
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog") \
    .config("spark.hadoop.fs.s3a.endpoint", "http://minio:9000") \
    .config("spark.hadoop.fs.s3a.access.key", "admin") \
    .config("spark.hadoop.fs.s3a.secret.key", "admin123") \
    .config("spark.hadoop.fs.s3a.path.style.access", "true") \
    .getOrCreate()

# 1. Ler da camada Bronze
bronze_df = spark.read.format("delta").load("s3a://bronze/raw_data_source1/table1")

# 2. Processar para Silver (limpeza e transforma√ß√£o)
silver_df = bronze_df \
    .dropDuplicates() \
    .filter(col("valor") > 0) \
    .withColumn("processed_date", current_date())

# 3. Salvar na camada Silver
silver_df.write.format("delta") \
    .mode("overwrite") \
    .save("s3a://silver/clean_data_domain1/table1")

# 4. Processar para Gold (agrega√ß√£o para an√°lise)
gold_df = silver_df \
    .groupBy("categoria", "regi√£o") \
    .agg(sum("valor").alias("valor_total")) \
    .orderBy(desc("valor_total"))

# 5. Salvar na camada Gold
gold_df.write.format("delta") \
    .mode("overwrite") \
    .save("s3a://gold/analytics_domain1/dashboard1")
```

### 2. Machine Learning com MLflow

```python
# No JupyterHub
import mlflow
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score

# Configurar MLflow
mlflow.set_tracking_uri("http://mlflow:5000")
mlflow.set_experiment("modelo-classificacao")

# Carregar dados da camada Silver
spark = SparkSession.builder.getOrCreate()
data = spark.read.format("delta").load("s3a://silver/clean_data_domain1/table1").toPandas()

# Preparar dados
X = data.drop("target_column", axis=1)
y = data["target_column"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Treinar com tracking do MLflow
with mlflow.start_run():
    # Configura√ß√µes do modelo
    params = {"n_estimators": 100, "max_depth": 10, "random_state": 42}
    mlflow.log_params(params)
    
    # Treinar modelo
    model = RandomForestClassifier(**params)
    model.fit(X_train, y_train)
    
    # Avaliar modelo
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    
    # Registrar m√©tricas
    mlflow.log_metric("accuracy", accuracy)
    mlflow.log_metric("precision", precision)
    mlflow.log_metric("recall", recall)
    
    # Registrar modelo
    mlflow.sklearn.log_model(model, "random_forest_model")
    
    print(f"Treinamento conclu√≠do - Acur√°cia: {accuracy:.4f}")
```

### 3. Orquestra√ß√£o com Prefect

```python
# No JupyterHub ou em um arquivo Python
from prefect import flow, task
from prefect.task_runners import SequentialTaskRunner
from pyspark.sql import SparkSession

@task(retries=3, retry_delay_seconds=30)
def extract_bronze_data(source):
    spark = SparkSession.builder.getOrCreate()
    return spark.read.format("delta").load(f"s3a://bronze/{source}")

@task
def transform_to_silver(df):
    from pyspark.sql.functions import current_timestamp, col
    
    return df.dropDuplicates() \
        .filter(col("valor") > 0) \
        .withColumn("processed_ts", current_timestamp())

@task
def load_to_silver(df, destination):
    df.write.format("delta") \
        .mode("overwrite") \
        .save(f"s3a://silver/{destination}")
    return f"s3a://silver/{destination}"

@flow(task_runner=SequentialTaskRunner())
def bronze_to_silver_etl(source="raw_data_source1/table1", destination="clean_data_domain1/table1"):
    # Extract
    raw_data = extract_bronze_data(source)
    
    # Transform
    transformed_data = transform_to_silver(raw_data)
    
    # Load
    result_path = load_to_silver(transformed_data, destination)
    
    return result_path

# Execu√ß√£o
if __name__ == "__main__":
    result = bronze_to_silver_etl()
    print(f"ETL conclu√≠do! Dados armazenados em: {result}")
```

## üìà Pain√©is e Visualiza√ß√µes

Crie visualiza√ß√µes interativas com Streamlit:

1. Acesse o Streamlit em [http://localhost:8501](http://localhost:8501)
2. Use os pain√©is pr√©-configurados ou crie novos com base nos dados das camadas Gold

## üîÑ Fluxos de Ingest√£o

Configure fluxos de ingest√£o de dados com Apache NiFi:

1. Acesse o NiFi em [https://localhost:8443/nifi](https://localhost:8443/nifi) (usu√°rio: nifi, senha: HGd15bvfv8744ghbdhgdv7895agqERAo)
2. Importe os templates de fluxo dispon√≠veis ou crie novos fluxos de ingest√£o

## üéØ Casos de Uso

O DataFlow Lab √© adequado para:

- **Engenharia de Dados**: Constru√ß√£o de pipelines ETL/ELT robustos
- **Data Science**: Experimenta√ß√£o, valida√ß√£o e deployment de modelos
- **Analytics**: Cria√ß√£o de pain√©is e relat√≥rios interativos
- **MLOps**: Ciclo completo de vida de modelos de machine learning
- **Streaming**: Processamento de dados em tempo real
- **Governan√ßa de Dados**: Cataloga√ß√£o e linhagem de dados

## üí° Funcionalidades Avan√ßadas

### 1. Integra√ß√£o com Contas Cloud

Para usar com provedores de nuvem, configure suas credenciais:

```yaml
# Em docker-compose.yml, adicione as vari√°veis de ambiente
environment:
  - AWS_ACCESS_KEY_ID=sua-chave
  - AWS_SECRET_ACCESS_KEY=sua-senha
```

### 2. Escalabilidade

Para escalar o processamento, ajuste os recursos no docker-compose.yml:

```yaml
services:
  spark-worker:
    deploy:
      replicas: 3  # Aumentar n√∫mero de workers
    environment:
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=8g
```

### 3. Seguran√ßa

Configure autentica√ß√£o e autoriza√ß√£o mais robustas:

```yaml
services:
  jupyterhub:
    environment:
      - JUPYTERHUB_ADMIN_USER=seunome
      - JUPYTERHUB_ADMIN_PASSWORD=senha-segura
```

## üõ†Ô∏è Manuten√ß√£o e Resolu√ß√£o de Problemas

### Comandos √öteis

```bash
# Ver logs de um servi√ßo
docker-compose logs -f [servi√ßo]

# Reiniciar um servi√ßo espec√≠fico
docker-compose restart [servi√ßo]

# Verificar uso de recursos
docker stats

# Parar todos os servi√ßos
docker-compose down

# Remover volumes (cuidado - apaga todos os dados)
docker-compose down -v
```

### Problemas Comuns

| Problema                  | Solu√ß√£o                                                             |
| ------------------------- | ------------------------------------------------------------------- |
| Erro de conex√£o com MinIO | Verifique se o servi√ßo est√° rodando e as credenciais est√£o corretas |
| Jupyter n√£o carrega       | Verifique logs e se h√° mem√≥ria suficiente dispon√≠vel                |
| Erro Spark Connection     | Verifique status do servi√ßo spark-master                            |
| Lentid√£o no processamento | Considere aumentar recursos dos workers                             |
| Falhas no MLflow          | Verifique conex√£o com o banco de dados do MLflow                    |

## ü§ù Contribui√ß√£o

Contribui√ß√µes s√£o bem-vindas! Para contribuir:

1. Fa√ßa um fork do projeto
2. Crie sua feature branch (`git checkout -b feature/amazing-feature`)
3. Commit suas altera√ß√µes (`git commit -m 'Add amazing feature'`)
4. Push para a branch (`git push origin feature/amazing-feature`)
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## üìö Recursos Adicionais

- [Documenta√ß√£o da Arquitetura Medallion](https://docs.databricks.com/lakehouse/medallion.html)
- [Guia do Delta Lake](https://docs.delta.io/latest/index.html)
- [MLflow Tracking](https://mlflow.org/docs/latest/tracking.html)
- [Prefect Documenta√ß√£o](https://docs.prefect.io/)
- [Apache Spark Guia](https://spark.apache.org/docs/latest/)
- [Streamlit Documenta√ß√£o](https://docs.streamlit.io/)
- [MinIO Reference](https://docs.min.io/)
- [Apache Kafka](https://kafka.apache.org/documentation/)
- [Apache NiFi Guide](https://nifi.apache.org/docs.html)
- [JupyterHub](https://jupyterhub.readthedocs.io/en/stable/)
