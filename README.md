# üöÄ DataLab - Plataforma Unificada de Dados

<div align="center">
  <img src="https://img.shields.io/badge/Python-3.8+-blue.svg" alt="Python">
  <img src="https://img.shields.io/badge/Prefect-3.4.1-purple.svg" alt="Prefect">
  <img src="https://img.shields.io/badge/Apache%20Spark-3.5-orange.svg" alt="Apache Spark">
  <img src="https://img.shields.io/badge/Docker-Required-blue.svg" alt="Docker">
  <img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License">
  <img src="https://img.shields.io/badge/Apache_Spark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white" alt="Apache Spark">
  <img src="https://img.shields.io/badge/Delta_Lake-00ADD8?style=for-the-badge&logo=delta&logoColor=white" alt="Delta Lake">
  <img src="https://img.shields.io/badge/MLflow-0194E2?style=for-the-badge&logo=mlflow&logoColor=white" alt="MLflow">
  <img src="https://img.shields.io/badge/MinIO-C72E49?style=for-the-badge&logo=minio&logoColor=white" alt="MinIO">
  <img src="https://img.shields.io/badge/Prefect-2EBDFA?style=for-the-badge&logo=prefect&logoColor=white" alt="Prefect">
  <img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white" alt="Streamlit">
</div>

> **DataLab** √© uma **plataforma unificada e robusta** para processamento, an√°lise e machine learning de dados. Integra as melhores ferramentas do ecossistema de dados em uma arquitetura coesa e escal√°vel, com orquestra√ß√£o centralizada via Prefect e gest√£o completamente unificada.

## üåü **Plataforma Unificada - Nova Arquitetura**

> **ÔøΩ EVOLU√á√ÉO COMPLETA**: O DataLab foi transformado em uma **plataforma verdadeiramente unificada** com arquitetura centralizada, CLI poderosa, monitoramento inteligente e gest√£o simplificada.

### ‚ú® **Principais Inova√ß√µes**

- **üèóÔ∏è Core Platform**: Sistema centralizado de gerenciamento de todos os servi√ßos
- **üéõÔ∏è CLI Unificada**: Interface de linha de comando completa (`datalab_cli.py`) 
- **üìä Dashboard Avan√ßado**: Interface web integrada com monitoramento em tempo real
- **üîÑ Orquestra√ß√£o Inteligente**: Gest√£o unificada de todos os pipelines via Prefect
- **üè• Health Monitoring**: Verifica√ß√µes autom√°ticas e m√©tricas de todos os servi√ßos
- **‚öôÔ∏è Configura√ß√£o Centralizada**: Sistema √∫nico de configura√ß√£o para toda a plataforma
- **üß™ Testes Automatizados**: Suite completa de valida√ß√£o e qualidade

## ÔøΩ **In√≠cio Ultra-R√°pido**

### **1. Setup Autom√°tico Completo** ‚ö°
```bash
# Clone e configure tudo automaticamente
git clone <repository-url> && cd datalab
./setup.sh && ./start_platform.sh
```

### **2. Acesso Imediato** üåê
```bash
# Dashboard Principal (Interface Unificada)
http://localhost:8501

# Servi√ßos Integrados
http://localhost:9001  # MinIO Console (admin/password123)
http://localhost:5000  # MLflow UI
http://localhost:8000  # JupyterHub (admin/admin) 
http://localhost:4200  # Prefect UI
http://localhost:4040  # Spark UI
```

### **3. Gest√£o Via CLI** üíª
```bash
# Status geral da plataforma
python datalab_cli.py platform status

# Executar pipeline ETL completo
python datalab_cli.py pipelines run medallion_etl

# Health check de todos os servi√ßos
python datalab_cli.py platform health

# Gest√£o de servi√ßos
python datalab_cli.py services list
python datalab_cli.py services restart spark
```
- **üóÑÔ∏è Data Lake**: MinIO (storage S3-compatible + Delta Lake)
- **üß™ ML Tracking**: MLflow 2.22.0 (experimentos e model registry)
- **üìä Dashboards**: Streamlit 1.45.0 (interface web interativa)
- **üìì Notebooks**: JupyterHub 5.3.0 (ambiente colaborativo)
- **üê≥ Containeriza√ß√£o**: Docker Compose (orquestra√ß√£o de servi√ßos)

### üèõÔ∏è **Arquitetura Medallion Avan√ßada**
- **ü•â Bronze**: Ingest√£o de dados brutos com metadados completos
- **ü•à Silver**: Dados limpos e transformados com valida√ß√£o de qualidade
- **ü•á Gold**: Agrega√ß√µes e m√©tricas prontas para an√°lise e ML
- **üìà Analytics**: Insights automatizados e relat√≥rios inteligentes

## üìã Componentes

| Componente       | Vers√£o                       | Porta       | Descri√ß√£o                              | Documenta√ß√£o                               |
| ---------------- | ---------------------------- | ----------- | -------------------------------------- | ------------------------------------------ |
| **Apache Spark** | 3.5.1                        | 8080, 7077  | Processamento distribu√≠do de dados     | [Documenta√ß√£o](/docs/spark/README.md)      |
| **Delta Lake**   | 3.3.1                        | -           | Camada de armazenamento para lakehouse | [Documenta√ß√£o](/docs/spark/README.md)      |
| **MLflow**       | 2.22.0                       | 5000        | Plataforma de MLOps                    | [Documenta√ß√£o](/docs/mlflow/README.md)     |
| **MinIO**        | RELEASE.2025-04-22T22-12-26Z | 9000, 9001  | Armazenamento de objetos S3            | [Documenta√ß√£o](/docs/minio/README.md)      |
| **Prefect**      | 3.4.1                        | 4200        | Orquestra√ß√£o de fluxos                 | [Documenta√ß√£o](/docs/prefect/README.md)    |
| **Streamlit**    | 1.45.0                       | 8501        | Dashboards interativos                 | [Documenta√ß√£o](/docs/streamlit/README.md)  |
| **JupyterHub**   | 4.0.2                        | 8000        | Ambiente de desenvolvimento            | [Documenta√ß√£o](/docs/jupyterhub/README.md) |
| **Apache Kafka** | 7.5.0                        | 9092, 29092 | Streaming de eventos                   | [Documenta√ß√£o](/docs/kafka/README.md)      |
| **Apache NiFi**  | 2.4.0                        | 8443        | Automa√ß√£o de fluxo de dados            | [Documenta√ß√£o](/docs/nifi/README.md)       |
| **Consul**       | 1.16.0                       | 8500, 8600  | Service Discovery                      | [Documenta√ß√£o](/docs/ARCHITECTURE.md)      |
| **Prometheus**   | latest                       | 9090        | Monitoramento de m√©tricas              | [Documenta√ß√£o](/docs/ARCHITECTURE.md)      |
| **Grafana**      | latest                       | 3000        | Visualiza√ß√£o de m√©tricas               | [Documenta√ß√£o](/docs/ARCHITECTURE.md)      |

## üèóÔ∏è Arquitetura

A arquitetura do DataFlow Lab √© baseada no padr√£o Medallion (Lakehouse), organizada em tr√™s camadas principais:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          CAMADA DE INGEST√ÉO                         ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Apache  ‚îÇ    ‚îÇ  Apache   ‚îÇ    ‚îÇ  APIs/ ‚îÇ    ‚îÇ     Outros     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   NiFi   ‚îÇ    ‚îÇ   Kafka   ‚îÇ    ‚îÇ  REST  ‚îÇ    ‚îÇ    Coletores   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ       ‚îÇ                ‚îÇ               ‚îÇ                 ‚îÇ          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                ‚îÇ               ‚îÇ                 ‚îÇ
        ‚ñº                ‚ñº               ‚ñº                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ
‚îÇ                   ‚îÇ       BRONZE LAYER      ‚îÇ                       ‚îÇ
‚îÇ                   ‚îÇ    (Dados Brutos em     ‚îÇ                       ‚îÇ
‚îÇ                   ‚îÇ     Formato Delta)      ‚îÇ                       ‚îÇ
‚îÇ                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
‚îÇ                                ‚îÇ                                    ‚îÇ
‚îÇ                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ
‚îÇ                   ‚îÇ       SILVER LAYER      ‚îÇ                       ‚îÇ
‚îÇ                   ‚îÇ   (Dados Limpos com     ‚îÇ                       ‚îÇ
‚îÇ                   ‚îÇ  Qualidade Garantida)   ‚îÇ                       ‚îÇ
‚îÇ                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
‚îÇ                                ‚îÇ                                    ‚îÇ
‚îÇ                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                       ‚îÇ
‚îÇ                   ‚îÇ        GOLD LAYER       ‚îÇ                       ‚îÇ
‚îÇ                   ‚îÇ  (Dados Agregados para  ‚îÇ                       ‚îÇ
‚îÇ                   ‚îÇ        Consumo)         ‚îÇ                       ‚îÇ
‚îÇ                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                       ‚îÇ
‚îÇ                             MINIO                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                ‚îÇ               ‚îÇ                 ‚îÇ
        ‚ñº                ‚ñº               ‚ñº                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          CAMADA DE CONSUMO                          ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇStreamlit ‚îÇ    ‚îÇ  MLflow   ‚îÇ    ‚îÇ Apache ‚îÇ    ‚îÇ    Outros      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇDashboards‚îÇ    ‚îÇ  Models   ‚îÇ    ‚îÇ Spark  ‚îÇ    ‚îÇ  Consumidores  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

A arquitetura Medallion possui tr√™s camadas principais:

1. **Bronze**: Dados brutos ingeridos exatamente como foram recebidos
2. **Silver**: Dados limpos, validados e transformados
3. **Gold**: Dados agregados e preparados para consumo por aplica√ß√µes

## üöÄ Como Come√ßar

### Pr√©-requisitos

- Docker
- Docker Compose
- Git

### Instala√ß√£o e Inicializa√ß√£o

1. Clone o reposit√≥rio:
   ```bash
   git clone https://github.com/seuusuario/datalab.git
   cd datalab
   ```

2. Inicie os servi√ßos:
   ```bash
   docker-compose up -d
   ```

3. Acesse os componentes pelos seguintes URLs (ap√≥s alguns minutos para inicializa√ß√£o):
   - JupyterHub: [http://localhost:8000](http://localhost:8000) (admin/admin)
   - MinIO Console: [http://localhost:9001](http://localhost:9001) (admin/admin123)
   - Apache Spark UI: [http://localhost:8080](http://localhost:8080)
   - MLflow UI: [http://localhost:5000](http://localhost:5000)
   - Prefect UI: [http://localhost:4200](http://localhost:4200)
   - Streamlit: [http://localhost:8501](http://localhost:8501)
   - Apache NiFi: [https://localhost:8443/nifi](https://localhost:8443/nifi) (nifi/HGd15bvfv8744ghbdhgdv7895agqERAo)
   - Kafka UI: [http://localhost:8090](http://localhost:8090)
   - Consul: [http://localhost:8500](http://localhost:8500)

### Inicializando os Buckets MinIO

Os buckets do MinIO s√£o inicializados automaticamente na primeira execu√ß√£o. Se necess√°rio, voc√™ pode inicializ√°-los manualmente:

```bash
./scripts/init_minio.sh
```

## üìö Tutoriais e Exemplos

### JupyterHub

O JupyterHub cont√©m v√°rios notebooks de exemplo para ajud√°-lo a come√ßar:

1. Autentique-se em [http://localhost:8000](http://localhost:8000) com as credenciais `admin`/`admin`
2. Navegue at√© a pasta `examples/` para ver os notebooks de exemplo
3. Comece com o notebook `medallion_architecture.ipynb` para uma vis√£o geral da arquitetura

### Exemplos de Arquitetura Medallion

- **Ingest√£o para Bronze**: Consulte o notebook `examples/bronze_ingestion.ipynb`
- **Processamento Bronze para Silver**: Consulte o notebook `examples/silver_processing.ipynb`
- **Agrega√ß√µes Silver para Gold**: Consulte o notebook `examples/gold_aggregations.ipynb`

## üìã Casos de Uso Comuns

### 1. Processamento de Dados Completo

```python
# No JupyterHub, usando PySpark com Delta Lake
from pyspark.sql import SparkSession
from pyspark.sql.functions import *

# Inicializa√ß√£o do Spark com suporte a Delta
spark = SparkSession.builder \
    .appName("MedallionExample") \
    .config("spark.sql.extensions", "io.delta.sql.DeltaSparkSessionExtension") \
    .config("spark.sql.catalog.spark_catalog", "org.apache.spark.sql.delta.catalog.DeltaCatalog") \
    .config("spark.hadoop.fs.s3a.endpoint", "http://minio:9000") \
    .config("spark.hadoop.fs.s3a.access.key", "admin") \
    .config("spark.hadoop.fs.s3a.secret.key", "admin123") \
    .config("spark.hadoop.fs.s3a.path.style.access", "true") \
    .getOrCreate()

# 1. Ler da camada Bronze
bronze_df = spark.read.format("delta").load("s3a://bronze/raw_data_source1/table1")

# 2. Processar para Silver (limpeza e transforma√ß√£o)
silver_df = bronze_df \
    .dropDuplicates() \
    .filter(col("valor") > 0) \
    .withColumn("processed_date", current_date())

# 3. Salvar na camada Silver
silver_df.write.format("delta") \
    .mode("overwrite") \
    .save("s3a://silver/clean_data_domain1/table1")

# 4. Processar para Gold (agrega√ß√£o para an√°lise)
gold_df = silver_df \
    .groupBy("categoria", "regi√£o") \
    .agg(sum("valor").alias("valor_total")) \
    .orderBy(desc("valor_total"))

# 5. Salvar na camada Gold
gold_df.write.format("delta") \
    .mode("overwrite") \
    .save("s3a://gold/analytics_domain1/dashboard1")
```

### 2. Machine Learning com MLflow

```python
# No JupyterHub
import mlflow
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score

# Configurar MLflow
mlflow.set_tracking_uri("http://mlflow:5000")
mlflow.set_experiment("modelo-classificacao")

# Carregar dados da camada Silver
spark = SparkSession.builder.getOrCreate()
data = spark.read.format("delta").load("s3a://silver/clean_data_domain1/table1").toPandas()

# Preparar dados
X = data.drop("target_column", axis=1)
y = data["target_column"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Treinar com tracking do MLflow
with mlflow.start_run():
    # Configura√ß√µes do modelo
    params = {"n_estimators": 100, "max_depth": 10, "random_state": 42}
    mlflow.log_params(params)
    
    # Treinar modelo
    model = RandomForestClassifier(**params)
    model.fit(X_train, y_train)
    
    # Avaliar modelo
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    
    # Registrar m√©tricas
    mlflow.log_metric("accuracy", accuracy)
    mlflow.log_metric("precision", precision)
    mlflow.log_metric("recall", recall)
    
    # Registrar modelo
    mlflow.sklearn.log_model(model, "random_forest_model")
    
    print(f"Treinamento conclu√≠do - Acur√°cia: {accuracy:.4f}")
```

### 3. Orquestra√ß√£o com Prefect

```python
# No JupyterHub ou em um arquivo Python
from prefect import flow, task
from prefect.task_runners import SequentialTaskRunner
from pyspark.sql import SparkSession

@task(retries=3, retry_delay_seconds=30)
def extract_bronze_data(source):
    spark = SparkSession.builder.getOrCreate()
    return spark.read.format("delta").load(f"s3a://bronze/{source}")

@task
def transform_to_silver(df):
    from pyspark.sql.functions import current_timestamp, col
    
    return df.dropDuplicates() \
        .filter(col("valor") > 0) \
        .withColumn("processed_ts", current_timestamp())

@task
def load_to_silver(df, destination):
    df.write.format("delta") \
        .mode("overwrite") \
        .save(f"s3a://silver/{destination}")
    return f"s3a://silver/{destination}"

@flow(task_runner=SequentialTaskRunner())
def bronze_to_silver_etl(source="raw_data_source1/table1", destination="clean_data_domain1/table1"):
    # Extract
    raw_data = extract_bronze_data(source)
    
    # Transform
    transformed_data = transform_to_silver(raw_data)
    
    # Load
    result_path = load_to_silver(transformed_data, destination)
    
    return result_path

# Execu√ß√£o
if __name__ == "__main__":
    result = bronze_to_silver_etl()
    print(f"ETL conclu√≠do! Dados armazenados em: {result}")
```

## üîÑ Orquestra√ß√£o com Prefect

O DataFlow Lab utiliza **Prefect 3.4.1** como orquestrador principal para todos os pipelines de dados. A arquitetura de orquestra√ß√£o inclui:

### Fluxos Principais

| Fluxo                       | Descri√ß√£o                                 | Agendamento       | Dura√ß√£o M√©dia |
| --------------------------- | ----------------------------------------- | ----------------- | ------------- |
| **Medallion ETL Pipeline**  | Pipeline completo Bronze ‚Üí Silver ‚Üí Gold  | Di√°rio √†s 06:00   | 12m 45s       |
| **Real-time Monitoring**    | Monitoramento da plataforma em tempo real | A cada 5 minutos  | 2m 15s        |
| **MLOps Training Pipeline** | Retreinamento semanal de modelos ML       | Domingos √†s 02:00 | 35m 20s       |
| **Data Lake Maintenance**   | Limpeza e otimiza√ß√£o do Data Lake         | S√°bados √†s 03:00  | 18m 32s       |

### Recursos do Prefect

- ‚úÖ **Observabilidade Completa**: Logs detalhados, m√©tricas e dashboards
- üîÑ **Retry Autom√°tico**: Pol√≠ticas de retry configur√°veis por task
- üìä **UI Web Moderna**: Interface intuitiva para monitoramento
- üö® **Alertas Inteligentes**: Notifica√ß√µes autom√°ticas de falhas
- üìà **Escalabilidade**: Suporte a workers distribu√≠dos
- üîß **API REST**: Integra√ß√£o program√°tica completa

### Arquitetura de Orquestra√ß√£o

```mermaid
graph TD
    A[Prefect Server] --> B[Work Pool]
    B --> C[Prefect Worker 1]
    B --> D[Prefect Worker 2]
    
    C --> E[ETL Tasks]
    C --> F[Monitoring Tasks]
    D --> G[MLOps Tasks]
    D --> H[Maintenance Tasks]
    
    E --> I[Spark Cluster]
    F --> J[Service Health Checks]
    G --> K[MLflow Registry]
    H --> L[Data Lake Cleanup]
    
    I --> M[Delta Lake]
    J --> N[Kafka/MinIO]
    K --> O[Model Deployment]
    L --> M
```

## üìà Pain√©is e Visualiza√ß√µes

Crie visualiza√ß√µes interativas com Streamlit:

1. Acesse o Streamlit em [http://localhost:8501](http://localhost:8501)
2. Use os pain√©is pr√©-configurados ou crie novos com base nos dados das camadas Gold

## üîÑ Fluxos de Ingest√£o

Configure fluxos de ingest√£o de dados com Apache NiFi:

1. Acesse o NiFi em [https://localhost:8443/nifi](https://localhost:8443/nifi) (usu√°rio: nifi, senha: HGd15bvfv8744ghbdhgdv7895agqERAo)
2. Importe os templates de fluxo dispon√≠veis ou crie novos fluxos de ingest√£o

## üéØ Casos de Uso

O DataFlow Lab √© adequado para:

- **Engenharia de Dados**: Constru√ß√£o de pipelines ETL/ELT robustos
- **Data Science**: Experimenta√ß√£o, valida√ß√£o e deployment de modelos
- **Analytics**: Cria√ß√£o de pain√©is e relat√≥rios interativos
- **MLOps**: Ciclo completo de vida de modelos de machine learning
- **Streaming**: Processamento de dados em tempo real
- **Governan√ßa de Dados**: Cataloga√ß√£o e linhagem de dados

## üí° Funcionalidades Avan√ßadas

### 1. Integra√ß√£o com Contas Cloud

Para usar com provedores de nuvem, configure suas credenciais:

```yaml
# Em docker-compose.yml, adicione as vari√°veis de ambiente
environment:
  - AWS_ACCESS_KEY_ID=sua-chave
  - AWS_SECRET_ACCESS_KEY=sua-senha
```

### 2. Escalabilidade

Para escalar o processamento, ajuste os recursos no docker-compose.yml:

```yaml
services:
  spark-worker:
    deploy:
      replicas: 3  # Aumentar n√∫mero de workers
    environment:
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=8g
```

### 3. Seguran√ßa

Configure autentica√ß√£o e autoriza√ß√£o mais robustas:

```yaml
services:
  jupyterhub:
    environment:
      - JUPYTERHUB_ADMIN_USER=seunome
      - JUPYTERHUB_ADMIN_PASSWORD=senha-segura
```

## üõ†Ô∏è Manuten√ß√£o e Resolu√ß√£o de Problemas

### Comandos √öteis

```bash
# Ver logs de um servi√ßo
docker-compose logs -f [servi√ßo]

# Reiniciar um servi√ßo espec√≠fico
docker-compose restart [servi√ßo]

# Verificar uso de recursos
docker stats

# Parar todos os servi√ßos
docker-compose down

# Remover volumes (cuidado - apaga todos os dados)
docker-compose down -v
```

### Problemas Comuns

| Problema                  | Solu√ß√£o                                                             |
| ------------------------- | ------------------------------------------------------------------- |
| Erro de conex√£o com MinIO | Verifique se o servi√ßo est√° rodando e as credenciais est√£o corretas |
| Jupyter n√£o carrega       | Verifique logs e se h√° mem√≥ria suficiente dispon√≠vel                |
| Erro Spark Connection     | Verifique status do servi√ßo spark-master                            |
| Lentid√£o no processamento | Considere aumentar recursos dos workers                             |
| Falhas no MLflow          | Verifique conex√£o com o banco de dados do MLflow                    |

## ü§ù Contribui√ß√£o

Contribui√ß√µes s√£o bem-vindas! Para contribuir:

1. Fa√ßa um fork do projeto
2. Crie sua feature branch (`git checkout -b feature/amazing-feature`)
3. Commit suas altera√ß√µes (`git commit -m 'Add amazing feature'`)
4. Push para a branch (`git push origin feature/amazing-feature`)
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para mais detalhes.

## üìä An√°lise T√©cnica do Projeto

### **üéØ Vis√£o Geral da Arquitetura**
O DataFlow Lab √© um **ambiente completo de desenvolvimento para engenharia de dados, ci√™ncia de dados e MLOps** que integra as principais ferramentas open source em uma plataforma unificada. O projeto implementa a **arquitetura Medallion** (Bronze, Silver, Gold) para processamento de dados em larga escala.

### **üèóÔ∏è Pontos Fortes da Arquitetura**

#### **Arquitetura Desacoplada e Modular:**
- **Servi√ßos organizados por funcionalidade**: Docker Compose separados para cada dom√≠nio
- **Service Discovery com Consul**: Descoberta autom√°tica de servi√ßos
- **Balanceamento de carga**: Spark Workers com 3 r√©plicas
- **Escalabilidade horizontal**: F√°cil adi√ß√£o de novos workers e servi√ßos

#### **Stack Tecnol√≥gica Moderna:**
```
Processamento: Apache Spark 3.5.1 + Delta Lake 3.3.1
Armazenamento: MinIO (S3-compatible) com arquitetura Medallion
Streaming: Apache Kafka 7.5.0 + Spark Structured Streaming
MLOps: MLflow 2.22.0 + Prefect 3.4.1
Orquestra√ß√£o: Apache NiFi 2.4.0 + Airflow
Visualiza√ß√£o: Streamlit 1.45.0 + JupyterHub 4.0.2
Monitoramento: Prometheus + Grafana + Consul
```

### **‚úÖ Implementa√ß√µes Avan√ßadas**

#### **1. Resili√™ncia e Robustez:**
- **Retry patterns**: Implementados com backoff exponencial
- **Health checks**: Configurados para todos os servi√ßos cr√≠ticos
- **Volumes persistentes**: Dados preservados entre reinicializa√ß√µes
- **Configura√ß√µes de timeout**: Conex√µes otimizadas para resili√™ncia

#### **2. Integra√ß√£o Seamless:**
```python
# Exemplo de pipeline completo Bronze ‚Üí Silver ‚Üí Gold
bronze_df = spark.read.format("delta").load("s3a://bronze/raw_data")
silver_df = bronze_df.transform(clean_and_validate)
gold_df = silver_df.aggregate(business_metrics)
```

#### **3. Streaming em Tempo Real:**
- **Kafka ‚Üî Spark Streaming**: Pipeline de dados em tempo real
- **Checkpointing**: Recupera√ß√£o autom√°tica de falhas
- **Event-driven architecture**: Processamento baseado em eventos

### **üìà Avalia√ß√£o por Componente**

| Componente       | Nota | Implementa√ß√£o  | Observa√ß√µes                                  |
| ---------------- | ---- | -------------- | -------------------------------------------- |
| **Apache Spark** | 9/10 | ‚úÖ Excelente    | Configura√ß√£o otimizada, Delta Lake integrado |
| **Delta Lake**   | 9/10 | ‚úÖ Completa     | Arquitetura Medallion bem implementada       |
| **MLflow**       | 8/10 | ‚úÖ Funcional    | Tracking e registry funcionais               |
| **Kafka**        | 8/10 | ‚úÖ Robusto      | UI inclu√≠da, bem configurado                 |
| **MinIO**        | 9/10 | ‚úÖ Otimizado    | S3-compatible, buckets organizados           |
| **Prefect**      | 8/10 | ‚úÖ Moderno      | Boa alternativa ao Airflow                   |
| **JupyterHub**   | 8/10 | ‚úÖ Colaborativo | Multi-usu√°rio, kernels configurados          |
| **NiFi**         | 7/10 | ‚úÖ B√°sico       | Funcional mas poderia ter mais templates     |

### **üîß Casos de Uso Implementados**

#### **1. ETL Completo (Bronze ‚Üí Silver ‚Üí Gold):**
```python
# Pipeline de processamento em 3 camadas
raw_data ‚Üí clean_data ‚Üí business_metrics
```

#### **2. MLOps Pipeline:**
```python
# Ciclo completo de ML
data_prep ‚Üí model_training ‚Üí mlflow_tracking ‚Üí model_registry ‚Üí deployment
```

#### **3. Streaming Analytics:**
```python
# Processamento em tempo real
kafka_source ‚Üí spark_streaming ‚Üí delta_sink ‚Üí real_time_dashboard
```

### **‚ö†Ô∏è √Åreas de Melhoria Identificadas**

#### **1. Seguran√ßa (Prioridade Alta):**
- ‚ùå Credenciais hardcoded em alguns arquivos
- ‚ùå Aus√™ncia de SSL/TLS em comunica√ß√µes internas
- ‚ùå Autentica√ß√£o b√°sica entre servi√ßos
- **Recomenda√ß√£o**: Implementar HashiCorp Vault ou similar

#### **2. Monitoramento (Prioridade M√©dia):**
- ‚ö†Ô∏è Dashboards b√°sicos no Grafana
- ‚ö†Ô∏è Logs n√£o centralizados
- ‚ö†Ô∏è Alertas autom√°ticos ausentes
- **Recomenda√ß√£o**: Implementar ELK Stack + alertas

#### **3. Testes e CI/CD (Prioridade M√©dia):**
- ‚ùå Aus√™ncia de testes automatizados
- ‚ùå N√£o h√° pipeline de CI/CD
- ‚ùå Valida√ß√£o de dados limitada
- **Recomenda√ß√£o**: GitHub Actions + pytest + Great Expectations

#### **4. Documenta√ß√£o (Prioridade Baixa):**
- ‚ö†Ô∏è Falta troubleshooting centralizado
- ‚ö†Ô∏è APIs n√£o documentadas
- ‚ö†Ô∏è Poucos exemplos de casos reais

### **üèÜ Avalia√ß√£o Geral: 8.5/10**

#### **Pontos Fortes:**
- ‚úÖ Arquitetura moderna e bem estruturada
- ‚úÖ Stack tecnol√≥gica atual e relevante
- ‚úÖ Separa√ß√£o clara de responsabilidades
- ‚úÖ Documenta√ß√£o abrangente por componente
- ‚úÖ Facilidade de setup e uso
- ‚úÖ Implementa√ß√£o completa da arquitetura Medallion
- ‚úÖ Resili√™ncia e retry patterns implementados

#### **Pontos a Melhorar:**
- ‚ö†Ô∏è Aspectos de seguran√ßa necessitam aten√ß√£o
- ‚ö†Ô∏è Monitoramento pode ser mais robusto
- ‚ö†Ô∏è Testes automatizados ausentes
- ‚ö†Ô∏è Performance tuning para produ√ß√£o

### **üöÄ Roadmap Sugerido**

#### **Fase 1 - Seguran√ßa (1-2 meses):**
1. Implementar gest√£o de secrets (Vault/Docker Secrets)
2. Configurar SSL/TLS entre servi√ßos
3. Implementar autentica√ß√£o robusta (OAuth2/LDAP)

#### **Fase 2 - Monitoramento (2-3 meses):**
1. Implementar ELK Stack para logs centralizados
2. Configurar alertas autom√°ticos (PagerDuty/Slack)
3. Criar dashboards avan√ßados no Grafana

#### **Fase 3 - Qualidade (3-4 meses):**
1. Implementar testes automatizados (pytest + Docker)
2. Configurar CI/CD pipeline (GitHub Actions)
3. Adicionar valida√ß√£o de dados (Great Expectations)

#### **Fase 4 - Produ√ß√£o (4-6 meses):**
1. Otimiza√ß√£o de performance
2. Backup automatizado
3. Disaster recovery
4. Documenta√ß√£o de opera√ß√£o

### **üíº Adequa√ß√£o para Diferentes Cen√°rios**

| Cen√°rio                | Adequa√ß√£o | Observa√ß√µes                                    |
| ---------------------- | --------- | ---------------------------------------------- |
| **Aprendizado/Estudo** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê     | Excelente para aprender stack moderna          |
| **Desenvolvimento**    | ‚≠ê‚≠ê‚≠ê‚≠ê‚ö™     | Muito bom, falta apenas alguns testes          |
| **Produ√ß√£o (pequena)** | ‚≠ê‚≠ê‚≠ê‚ö™‚ö™     | Poss√≠vel, mas necessita melhorias de seguran√ßa |
| **Produ√ß√£o (grande)**  | ‚≠ê‚≠ê‚ö™‚ö™‚ö™     | Requer trabalho significativo de hardening     |

### **üéØ Conclus√£o**

O DataFlow Lab √© um **projeto impressionante** que demonstra uma compreens√£o s√≥lida de engenharia de dados moderna. √â uma **excelente plataforma para aprendizado e desenvolvimento**, com grande potencial para evolu√ß√£o para ambiente produtivo.

**Destaques:**
- Implementa√ß√£o completa da arquitetura Medallion
- Integra√ß√£o harmoniosa entre componentes
- Documenta√ß√£o detalhada e exemplos pr√°ticos
- Facilidade de uso e setup
- Arquitetura preparada para escala

O projeto est√° bem posicionado para ser uma refer√™ncia em ambientes de dados modernos, precisando apenas de alguns ajustes em seguran√ßa e monitoramento para uso em produ√ß√£o.

## üöÄ Nova Arquitetura Escalon√°vel

A partir de maio de 2025, o DataFlow Lab implementou uma arquitetura mais escalon√°vel e desacoplada:

### Desacoplamento por Funcionalidade

Os servi√ßos agora est√£o organizados em arquivos Docker Compose separados:

- **docker-compose.core.yml**: Servi√ßos de infraestrutura (MinIO, Kafka, Consul)
- **docker-compose.processing.yml**: Processamento de dados (Spark, NiFi)
- **docker-compose.ml.yml**: Machine Learning (MLflow, Prefect, Airflow)
- **docker-compose.visualization.yml**: Visualiza√ß√£o (JupyterHub, Streamlit)
- **docker-compose.monitoring.yml**: Monitoramento (Prometheus, Grafana)

### Gerenciamento Simplificado

Use o script `scripts/manage_environments.sh` para gerenciar os ambientes:

```bash
# Iniciar apenas servi√ßos espec√≠ficos
./scripts/manage_environments.sh start core

# Iniciar m√∫ltiplos grupos de servi√ßos
./scripts/manage_environments.sh start core processing

# Iniciar todos os servi√ßos
./scripts/manage_environments.sh start all

# Verificar status
./scripts/manage_environments.sh status
```

### Balanceamento de Carga e Service Discovery

- Trabalhadores Spark configurados com 3 r√©plicas para balanceamento de carga
- Recursos de CPU e mem√≥ria garantidos para cada servi√ßo
- Consul configurado para service discovery entre todos os componentes

Para mais detalhes sobre a arquitetura, consulte a [documenta√ß√£o completa](/docs/ARCHITECTURE.md).
