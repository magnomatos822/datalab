# DataFlow Lab

<div align="center">
  <img src="https://img.shields.io/badge/Apache_Spark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white" alt="Apache Spark">
  <img src="https://img.shields.io/badge/MLflow-0194E2?style=for-the-badge&logo=mlflow&logoColor=white" alt="MLflow">
  <img src="https://img.shields.io/badge/Prefect-024DFD?style=for-the-badge&logo=prefect&logoColor=white" alt="Prefect">
  <img src="https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white" alt="Jupyter">
  <img src="https://img.shields.io/badge/MinIO-C72E49?style=for-the-badge&logo=minio&logoColor=white" alt="MinIO">
  <img src="https://img.shields.io/badge/Delta_Lake-00ADD8?style=for-the-badge&logo=delta&logoColor=white" alt="Delta Lake">
  <img src="https://img.shields.io/static/v1?style=for-the-badge&message=Apache+NiFi&color=728E9B&logo=Apache+NiFi&logoColor=FFFFFF&label=" alt="Apache NiFi">
  <img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white" alt="Streamlit">
  <img src="https://img.shields.io/badge/Airflow-017C74?style=for-the-badge&logo=apache-airflow&logoColor=white" alt="Apache Airflow">
  <img src="https://img.shields.io/badge/Kafka-231F20?style=for-the-badge&logo=apache-kafka&logoColor=white" alt="Apache Kafka">
</div>

<br>

> Arquitetura moderna de Data Lakehouse com pipeline de dados para engenharia de dados e machine learning â€” processamento em camadas (Bronze, Silver, Gold), garantias ACID, time travel, monitoramento e orquestraÃ§Ã£o.

## ğŸ“‹ SumÃ¡rio

- [DataFlow Lab](#dataflow-lab)
  - [ğŸ“‹ SumÃ¡rio](#-sumÃ¡rio)
  - [ğŸ”­ VisÃ£o Geral](#-visÃ£o-geral)
  - [ğŸ—ï¸ Arquitetura](#ï¸-arquitetura)
  - [ğŸ§© Componentes](#-componentes)
    - [Armazenamento de Dados](#armazenamento-de-dados)
    - [IngestÃ£o e ETL](#ingestÃ£o-e-etl)
    - [Processamento de Dados](#processamento-de-dados)
    - [Machine Learning](#machine-learning)
    - [OrquestraÃ§Ã£o](#orquestraÃ§Ã£o)
    - [Desenvolvimento](#desenvolvimento)
    - [VisualizaÃ§Ã£o](#visualizaÃ§Ã£o)
  - [ğŸš€ InÃ­cio RÃ¡pido](#-inÃ­cio-rÃ¡pido)
    - [PrÃ©-requisitos](#prÃ©-requisitos)
    - [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
    - [URLs dos ServiÃ§os](#urls-dos-serviÃ§os)
  - [ğŸ“‚ Estrutura do Projeto](#-estrutura-do-projeto)
  - [ğŸ“Š Uso do Sistema](#-uso-do-sistema)
    - [Arquitetura Medallion](#arquitetura-medallion)
    - [TransaÃ§Ãµes ACID com Delta Lake](#transaÃ§Ãµes-acid-com-delta-lake)
    - [Fluxo de Dados TÃ­pico](#fluxo-de-dados-tÃ­pico)
    - [Casos de Uso](#casos-de-uso)
    - [Exemplos PrÃ¡ticos](#exemplos-prÃ¡ticos)
  - [ğŸ”„ IntegraÃ§Ã£o com Apache NiFi](#-integraÃ§Ã£o-com-apache-nifi)
  - [ğŸ“ˆ Analytics com Spark e Kafka](#-analytics-com-spark-e-kafka)
  - [ğŸ‘¥ ContribuiÃ§Ã£o](#-contribuiÃ§Ã£o)
  - [ğŸ“„ LicenÃ§a](#-licenÃ§a)

## ğŸ”­ VisÃ£o Geral

O DataFlow Lab Ã© uma plataforma completa de Data Lakehouse para processamento de dados, abrangendo desde a ingestÃ£o de dados brutos atÃ© a criaÃ§Ã£o de modelos de machine learning. A arquitetura implementa prÃ¡ticas modernas de engenharia de dados como processamento em camadas (Medallion: Bronze, Silver, Gold), transaÃ§Ãµes ACID atravÃ©s do Delta Lake, rastreabilidade e reprodutibilidade.

Atualizado em: **14 de maio de 2025**

## ğŸ—ï¸ Arquitetura

<pre>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          â”‚     â”‚          â”‚     â”‚          â”‚     â”‚          â”‚     â”‚            â”‚
â”‚   RAW    â”‚â”€â”€â”€â”€â–¶â”‚  BRONZE  â”‚â”€â”€â”€â”€â–¶â”‚  SILVER  â”‚â”€â”€â”€â”€â–¶â”‚   GOLD   â”‚â”€â”€â”€â”€â–¶â”‚  ML MODELS â”‚
â”‚   DATA   â”‚     â”‚  LAYER   â”‚     â”‚  LAYER   â”‚     â”‚  LAYER   â”‚     â”‚            â”‚
â”‚          â”‚     â”‚          â”‚     â”‚          â”‚     â”‚          â”‚     â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                â”‚                â”‚                â”‚                 â”‚
      â”‚                â”‚                â”‚                â”‚                 â”‚
      â–¼                â–¼                â–¼                â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                              â”‚
â”‚                          ACID TRANSACTIONS (Delta Lake)                      â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                â”‚                â”‚                â”‚                 â”‚
      â”‚                â”‚                â”‚                â”‚                 â”‚
      â–¼                â–¼                â–¼                â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                              â”‚
â”‚                         STREAMING (Kafka/Spark)                              â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                â”‚                â”‚                â”‚                 â”‚
      â”‚                â”‚                â”‚                â”‚                 â”‚
      â–¼                â–¼                â–¼                â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                              â”‚
â”‚                          WORKFLOW ORCHESTRATION                              â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</pre>

## ğŸ§© Componentes

O sistema Ã© composto por vÃ¡rios componentes integrados que formam uma plataforma completa de Data Lakehouse:

### Armazenamento de Dados
- **[MinIO](docs/minio/README.md)**: Sistema de armazenamento de objetos compatÃ­vel com Amazon S3
  - Console: [http://localhost:9001](http://localhost:9001) (admin/admin123)
  - API: [http://localhost:9000](http://localhost:9000)
  - Buckets: bronze, silver, gold (arquitetura Medallion)
  - **VersÃ£o**: 2025-04-22

### IngestÃ£o e ETL
- **[Apache NiFi](docs/nifi/README.md)**: Plataforma para automaÃ§Ã£o de fluxos de dados
  - UI: [https://localhost:8443](https://localhost:8443) (nifi/senha-configurada)
  - Drivers JDBC prÃ©-instalados para PostgreSQL, MySQL, Oracle
  - **VersÃ£o**: 2.4.0

### Processamento de Dados
- **[Apache Spark](docs/spark/README.md)**: Framework de processamento distribuÃ­do
  - Master UI: [http://localhost:8080](http://localhost:8080)
  - Worker UI: [http://localhost:8081](http://localhost:8081)
  - **VersÃ£o**: 3.5.5
- **[Delta Lake](docs/spark/README.md#delta-lake)**: Camada de armazenamento que traz transaÃ§Ãµes ACID para Spark
  - Formatos: delta (com garantias ACID)
  - Recursos: Time Travel, MERGE, Z-Order, Optimize
  - **VersÃ£o**: 3.3.1
- **[Apache Kafka](docs/kafka/README.md)**: Plataforma de streaming distribuÃ­do
  - Broker: [localhost:9092](localhost:9092)
  - Interface: [http://localhost:8090](http://localhost:8090)
  - **VersÃ£o**: 7.5.0

### Machine Learning
- **[MLflow](docs/mlflow/README.md)**: Plataforma para gerenciamento do ciclo de vida de ML
  - UI: [http://localhost:5000](http://localhost:5000)
  - Tracking, registros de modelos e serviÃ§o
  - IntegraÃ§Ã£o com MinIO para armazenamento de artefatos
  - **VersÃ£o**: 2.22.0

### OrquestraÃ§Ã£o
- **[Prefect](docs/prefect/README.md)**: Orquestrador de fluxos de dados
  - UI: [http://localhost:4200](http://localhost:4200)
  - Fluxos, tarefas e monitoramento
  - **VersÃ£o**: 3.4.1

### Desenvolvimento
- **[JupyterHub](docs/jupyterhub/README.md)**: Ambiente de desenvolvimento interativo multi-usuÃ¡rio
  - UI: [http://localhost:8888](http://localhost:8888)
  - Notebooks para anÃ¡lise exploratÃ³ria
  - **VersÃ£o**: 5.3.0

### VisualizaÃ§Ã£o
- **[Streamlit](docs/streamlit/README.md)**: Framework para criaÃ§Ã£o de aplicaÃ§Ãµes de dados
  - UI: [http://localhost:8501](http://localhost:8501)
  - Dashboards interativos
  - **VersÃ£o**: 1.45.0

## ğŸš€ InÃ­cio RÃ¡pido

### PrÃ©-requisitos

- Docker e Docker Compose instalados
- Git (opcional, para clonar o repositÃ³rio)
- Recomendado: 8GB+ de RAM e 20GB+ de espaÃ§o em disco

### InstalaÃ§Ã£o

1. Clone o repositÃ³rio (ou baixe como ZIP):
   ```bash
   git clone https://github.com/seu-usuario/dataflow-lab.git
   cd dataflow-lab
   ```

2. Crie um arquivo `.env` com as credenciais necessÃ¡rias:
   ```bash
   echo "MINIO_ROOT_USER=admin" > .env
   echo "MINIO_ROOT_PASSWORD=admin123" >> .env
   echo "AWS_ACCESS_KEY_ID=admin" >> .env
   echo "AWS_SECRET_ACCESS_KEY=admin123" >> .env
   ```

3. Inicie os serviÃ§os:
   ```bash
   docker-compose up -d
   ```

4. Verifique se todos os serviÃ§os estÃ£o rodando:
   ```bash
   docker-compose ps
   ```

   Para verificar os logs de um serviÃ§o especÃ­fico (por exemplo, Spark):
   ```bash
   docker-compose logs spark-master
   ```

### URLs dos ServiÃ§os

| ServiÃ§o      | URL                      | Credenciais      |
| ------------ | ------------------------ | ---------------- |
| MinIO        | http://localhost:9001    | admin/admin123   |
| Apache NiFi  | https://localhost:8443   | nifi/senha-config |
| Spark Master | http://localhost:8080    | -                |
| MLflow       | http://localhost:5000    | -                |
| Prefect UI   | http://localhost:4200    | -                |
| JupyterHub   | http://localhost:8888    | (token nos logs) |
| Streamlit    | http://localhost:8501    | -                |
| Kafka UI     | http://localhost:8090    | -                |

## ğŸ“‚ Estrutura do Projeto

```
dataflow-lab/
â”‚
â”œâ”€â”€ docker-compose.yml      # DefiniÃ§Ã£o dos serviÃ§os Docker
â”œâ”€â”€ jupyterhub_config.py    # ConfiguraÃ§Ã£o do JupyterHub
â”œâ”€â”€ README.md               # Este arquivo
â”œâ”€â”€ LICENSE                 # LicenÃ§a do projeto
â”œâ”€â”€ requirements.txt        # DependÃªncias Python (incluindo delta-spark)
â”‚
â”œâ”€â”€ app/                    # CÃ³digo Python da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ analytics.py               # FunÃ§Ãµes analÃ­ticas com Spark
â”‚   â”œâ”€â”€ app.py                     # AplicaÃ§Ã£o principal
â”‚   â”œâ”€â”€ medallion_architecture.py  # ImplementaÃ§Ã£o da arquitetura Medallion
â”‚   â”œâ”€â”€ medallion_example.py       # Exemplo de uso
â”‚   â”œâ”€â”€ medallion_prefect_flow.py  # Fluxos Prefect para orquestraÃ§Ã£o
â”‚   â”œâ”€â”€ mlflow.py                  # IntegraÃ§Ãµes com MLflow
â”‚   â””â”€â”€ tutorial.py                # Tutoriais e exemplos
â”‚
â”œâ”€â”€ docs/                   # DocumentaÃ§Ã£o detalhada
â”‚   â”œâ”€â”€ airflow/            # DocumentaÃ§Ã£o do Airflow
â”‚   â”œâ”€â”€ jupyterhub/         # DocumentaÃ§Ã£o do JupyterHub
â”‚   â”œâ”€â”€ kafka/              # DocumentaÃ§Ã£o do Kafka
â”‚   â”œâ”€â”€ minio/              # DocumentaÃ§Ã£o do MinIO
â”‚   â”œâ”€â”€ mlflow/             # DocumentaÃ§Ã£o do MLflow
â”‚   â”œâ”€â”€ nifi/               # DocumentaÃ§Ã£o do NiFi
â”‚   â”œâ”€â”€ prefect/            # DocumentaÃ§Ã£o do Prefect
â”‚   â”œâ”€â”€ spark/              # DocumentaÃ§Ã£o do Apache Spark e Delta Lake
â”‚   â””â”€â”€ streamlit/          # DocumentaÃ§Ã£o do Streamlit
â”‚
â”œâ”€â”€ notebooks/              # Jupyter notebooks de exemplo
â”‚   â”œâ”€â”€ jupyterhub_credentials.ipynb # InformaÃ§Ãµes de credenciais
â”‚   â”œâ”€â”€ magnomatos822/      # Notebooks do usuÃ¡rio
â”‚   â”‚   â””â”€â”€ amazon.ipynb    # AnÃ¡lise de dados da Amazon
â”‚   â”œâ”€â”€ nifi_tutorials/     # Tutoriais do NiFi
â”‚   â””â”€â”€ retail_analysis/    # AnÃ¡lise de dados de varejo
â”‚
â”œâ”€â”€ config/                 # Arquivos de configuraÃ§Ã£o
â”‚   â”œâ”€â”€ airflow/            # ConfiguraÃ§Ãµes do Airflow
â”‚   â”œâ”€â”€ jupyterhub/         # ConfiguraÃ§Ãµes do JupyterHub
â”‚   â”œâ”€â”€ mlflow/             # ConfiguraÃ§Ãµes do MLflow
â”‚   â”œâ”€â”€ spark/              # ConfiguraÃ§Ãµes do Spark
â”‚   â”‚   â””â”€â”€ conf/           # Arquivos de configuraÃ§Ã£o do Spark
â”‚   â””â”€â”€ streamlit/          # ConfiguraÃ§Ãµes do Streamlit
â”‚
â”œâ”€â”€ data/                   # DiretÃ³rio para armazenar dados
â”‚   â”œâ”€â”€ airflow/            # Dados do Airflow
â”‚   â”œâ”€â”€ jupyter/            # Dados do JupyterHub
â”‚   â”œâ”€â”€ minio/              # Buckets do MinIO (bronze, silver, gold)
â”‚   â”œâ”€â”€ mlflow/             # Dados do MLflow
â”‚   â”œâ”€â”€ nifi/               # Dados do NiFi
â”‚   â”œâ”€â”€ postgres/           # Dados do PostgreSQL
â”‚   â”œâ”€â”€ prefect/            # Dados do Prefect
â”‚   â””â”€â”€ spark/              # Logs e dados do Spark
â”‚
â”œâ”€â”€ flows/                  # DefiniÃ§Ãµes de fluxos Prefect
â”œâ”€â”€ mlruns/                 # DiretÃ³rio para armazenar artefatos do MLflow
â”‚   â””â”€â”€ models/             # Modelos treinados
â”‚
â”œâ”€â”€ models/                 # Modelos exportados
â”‚
â”œâ”€â”€ nifi/                   # Recursos para Apache NiFi
â”‚   â”œâ”€â”€ drivers/            # Drivers JDBC organizados por tipo de banco
â”‚   â””â”€â”€ jdbc/               # Drivers JDBC gerais
â”‚
â””â”€â”€ scripts/                # Scripts utilitÃ¡rios
    â”œâ”€â”€ download_spark_jars.sh  # Script para baixar JARs do Spark
    â””â”€â”€ init_minio.sh      # Script para inicializaÃ§Ã£o do MinIO
```

## ğŸ“Š Uso do Sistema

### Arquitetura Medallion

Nossa implementaÃ§Ã£o segue a arquitetura Medallion (tambÃ©m conhecida como multi-hop), organizada em trÃªs camadas principais:

1. **Bronze**: Dados brutos ingeridos sem modificaÃ§Ãµes ou com mÃ­nimas transformaÃ§Ãµes
   - Preserva os dados originais para auditoria e recuperaÃ§Ã£o
   - Inclui metadados como hora de ingestÃ£o e fonte

2. **Silver**: Dados limpos, validados e transformados
   - Dados normalizados e estruturados
   - Valores nulos tratados e anomalias removidas
   - Esquema consistente e documentado

3. **Gold**: Dados refinados e agregados para consumo
   - Tabelas e views preparadas para anÃ¡lise
   - Dados agregados e modelados para casos de uso especÃ­ficos
   - Otimizados para consulta e anÃ¡lise

### TransaÃ§Ãµes ACID com Delta Lake

O projeto implementa o Delta Lake para fornecer garantias ACID (Atomicidade, ConsistÃªncia, Isolamento, Durabilidade):

- **AtualizaÃ§Ãµes incrementais (MERGE)**: Capacidade de atualizar registros existentes e inserir novos em uma Ãºnica operaÃ§Ã£o atÃ´mica
- **Time Travel**: Acesso a versÃµes anteriores dos dados usando versÃ£o especÃ­fica ou timestamp
- **OtimizaÃ§Ã£o de tabelas**: CompactaÃ§Ã£o de arquivos pequenos e Z-Order para melhor performance de consulta
- **Schema Enforcement**: ValidaÃ§Ã£o automÃ¡tica de esquema para garantir qualidade dos dados
- **Gerenciamento de histÃ³rico**: Controle sobre retenÃ§Ã£o de versÃµes antigas para economia de espaÃ§o

### Fluxo de Dados TÃ­pico

1. **IngestÃ£o de Dados**: Coleta de dados de fontes diversas (APIs, bancos de dados, arquivos) usando NiFi
2. **Armazenamento Bronze**: Armazenamento dos dados brutos no formato Delta Lake (MinIO)
3. **Processamento Silver**: Limpeza e transformaÃ§Ã£o com Apache Spark
4. **Refinamento Gold**: AgregaÃ§Ãµes e modelagem para anÃ¡lise
5. **Modelagem**: Treinamento de modelos preditivos com rastreamento no MLflow
6. **OrquestraÃ§Ã£o**: AutomatizaÃ§Ã£o e agendamento de pipelines com Prefect
7. **VisualizaÃ§Ã£o**: Dashboards e aplicaÃ§Ãµes com Streamlit

### Casos de Uso

O DataFlow Lab foi projetado para suportar diversos casos de uso:

- **ETL e ELT modernos**: Processamento de dados com estrutura de medallion
- **Machine Learning**: Treinamento e implementaÃ§Ã£o de modelos com MLflow
- **AnÃ¡lise financeira**: Processamento de sÃ©ries temporais e dados financeiros
- **Processamento de logs**: AnÃ¡lise de logs e telemetria
- **IntegraÃ§Ã£o de dados**: UnificaÃ§Ã£o de fontes de dados heterogÃªneas
- **Analytics em tempo real**: Processamento de streaming com Kafka e Spark Structured Streaming

### Exemplos PrÃ¡ticos

Consulte nossos exemplos para casos de uso comuns:

- `/app/medallion_example.py`: Exemplo completo da arquitetura Medallion com Delta Lake
- `/app/medallion_prefect_flow.py`: OrquestraÃ§Ã£o do pipeline Medallion usando Prefect
- `/app/analytics.py`: AnÃ¡lises avanÃ§adas com Apache Spark
- `/notebooks/magnomatos822/amazon.ipynb`: AnÃ¡lise de dados financeiros da Amazon

Para executar o exemplo da arquitetura Medallion:

```bash
docker exec -it spark-master python /opt/spark-apps/medallion_prefect_flow.py
```

## ğŸ”„ IntegraÃ§Ã£o com Apache NiFi

O DataFlow Lab utiliza o Apache NiFi (2.4.0) para ingestÃ£o e transformaÃ§Ã£o de dados. As principais caracterÃ­sticas da integraÃ§Ã£o sÃ£o:

- **Interface segura**: Acesso via HTTPS em https://localhost:8443
- **Drivers prÃ©-configurados**: PostgreSQL, MySQL, MS SQL Server e Oracle
- **Fluxos de exemplo**: DisponÃ­veis na pasta `nifi/templates`
- **OrganizaÃ§Ã£o por tipo**: Drivers organizados por tipo de banco de dados

Para acessar o Apache NiFi:

1. Acesse [https://localhost:8443/nifi](https://localhost:8443/nifi)
2. Utilize as credenciais configuradas (padrÃ£o: nifi/senha-configurada)
3. Importe templates ou crie novos fluxos

Exemplo de NiFi para enviar dados para o Data Lake:
```
GetFile -> ExtractText -> ConvertJSONtoSQL -> PutS3Object
```

## ğŸ“ˆ Analytics com Spark e Kafka

O componente de analytics (`app/analytics.py`) fornece funÃ§Ãµes para anÃ¡lise de dados avanÃ§ada, agora com integraÃ§Ãµes Kafka:

- **AnÃ¡lise em tempo real**: Processamento de eventos em tempo real com Kafka
- **AnÃ¡lise de sÃ©ries temporais**: PrevisÃµes e detecÃ§Ã£o de tendÃªncias
- **DetecÃ§Ã£o de anomalias**: IdentificaÃ§Ã£o de padrÃµes incomuns
- **AnÃ¡lise de sentimento**: Processamento de texto com NLP
- **Analytics preditivos**: Modelos de machine learning avanÃ§ados

Exemplo de uso com Kafka:

```python
from app.analytics import StreamProcessor

# Configurar processador de streaming
processor = StreamProcessor(
    bootstrap_servers="kafka:9092",
    input_topic="raw_data",
    output_topic="processed_data"
)

# Definir transformaÃ§Ã£o
def transform(df):
    return df.withColumn("processed_value", df.value * 2)

# Iniciar processamento
processor.start_processing(transform)
```

## ğŸ‘¥ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor, siga estas etapas para contribuir:

1. Fork o repositÃ³rio
2. Crie um branch para sua feature (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas alteraÃ§Ãµes (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push para o branch (`git push origin feature/nova-funcionalidade`)
5. Crie um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto Ã© licenciado sob a [GNU General Public License v3.0](LICENSE) - veja o arquivo LICENSE para detalhes.
